{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "path = os.getcwd()\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,BaggingRegressor, StackingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + \"\\\\TRAIN.csv\", index_col = 'index')\n",
    "test = pd.read_csv(path + \"\\\\TEST.csv\", index_col = 'index')\n",
    "ss = pd.read_csv(path + \"\\\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['time_stamp'] = pd.to_datetime(train['time_stamp'], unit = 'ms')\n",
    "test['time_stamp'] = pd.to_datetime(test['time_stamp'], unit = 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hour\"] = pd.to_datetime(train.time_stamp, format=\"%Y-%m-%d\").dt.hour\n",
    "train[\"minute\"] = pd.to_datetime(train.time_stamp, format=\"%Y-%m-%d\").dt.minute\n",
    "train[\"day\"] = pd.to_datetime(train.time_stamp, format=\"%Y-%m-%d\").dt.day\n",
    "\n",
    "test[\"hour\"] = pd.to_datetime(test.time_stamp, format=\"%Y-%m-%d\").dt.hour\n",
    "test[\"minute\"] = pd.to_datetime(test.time_stamp, format=\"%Y-%m-%d\").dt.minute\n",
    "test[\"day\"] = pd.to_datetime(test.time_stamp, format=\"%Y-%m-%d\").dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis = 0).reset_index(drop=True)\n",
    "df['time_stamp'] = pd.to_datetime(df['time_stamp'], unit = 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "le = LabelEncoder()\n",
    "sl = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopy\n",
    "# from geopy.extra.rate_limiter import RateLimiter\n",
    "# from geopy.geocoders import Nominatim\n",
    "# import geopy.distance\n",
    "\n",
    "\n",
    "# geolocator = Nominatim(user_agent=\"http\")\n",
    "# states = df['source'].unique()\n",
    "# d = dict(zip(states, pd.Series(states).apply(geolocator.geocode).apply(lambda x: (x.latitude, x.longitude))))\n",
    "# lat =pd.DataFrame(d, index=['pickup_latitude','pickup_longitude']).T\n",
    "# Lat= lat.reset_index()\n",
    "# Lat['source']=Lat['index']\n",
    "# Lat.drop(columns=['index'],inplace=True)\n",
    "\n",
    "# df = pd.merge(df, Lat, how=\"left\") \n",
    "\n",
    "# states = df['destination'].unique()\n",
    "# d = dict(zip(states, pd.Series(states).apply(geolocator.geocode).apply(lambda x: (x.latitude, x.longitude))))\n",
    "# lat =pd.DataFrame(d, index=['dropoff_latitude','dropoff_longitude']).T\n",
    "# Lat= lat.reset_index()\n",
    "# Lat['destination']=Lat['index']\n",
    "# Lat.drop(columns=['index'],inplace=True)\n",
    "\n",
    "# df = pd.merge(df, Lat, how=\"left\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_distance_features(df):\n",
    "#     # Distance is expected to have an impact on the fare\n",
    "#     df['longitude_distance'] = abs(df['pickup_longitude'] - df['dropoff_longitude'])\n",
    "#     df['latitude_distance'] = abs(df['pickup_latitude'] - df['dropoff_latitude'])\n",
    "\n",
    "#     # Straight distance\n",
    "#     df['distance_travelled'] = (df['longitude_distance'] * 2 + df['latitude_distance'] * 2) ** .5\n",
    "#     df['distance_travelled_sin'] = np.sin((df['longitude_distance'] * 2 * df['latitude_distance'] * 2) ** .5)\n",
    "#     df['distance_travelled_cos'] = np.cos((df['longitude_distance'] * 2 * df['latitude_distance'] * 2) ** .5)\n",
    "# #     df['distance_travelled_sin_sqrd'] = np.sin((df['longitude_distance'] * 2 * df['latitude_distance'] * 2) * .5) * 2\n",
    "# #     df['distance_travelled_cos_sqrd'] = np.cos((df['longitude_distance'] * 2 * df['latitude_distance'] * 2) * .5) * 2\n",
    "\n",
    "#     return df\n",
    "\n",
    "# df = prepare_distance_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'Theatre District': 1, 'Fenway': 2, 'Beacon Hill': 3,\n",
    "        'North End': 4, 'Northeastern University': 5, 'Financial District': 6,\n",
    "        'Boston University': 7, 'Haymarket Square': 8, 'West End': 9,\n",
    "        'South Station': 10, 'North Station': 11, 'Back Bay': 12}\n",
    "\n",
    "df['source'] = df['source'].map(dict_)\n",
    "df['destination'] = df['destination'].map(dict_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['cab_provider', 'cab_type']\n",
    "\n",
    "df[label_cols] = df[label_cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc, test_proc = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'fare'\n",
    "time = 'time_stamp'\n",
    "time_feats = ['hour', 'year', 'minute', 'day','dayofweek', 'month', 'weekday']\n",
    "\n",
    "features = [col for col in train_proc.columns if col not in [target, time]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "trn, val = train_test_split(train_proc, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test_proc[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 1.7010355358395521\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = XGBRegressor(random_state=1999)\n",
    "\n",
    "lgb.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lgb.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'mean_squared_log_error is : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 1.7725443389889546\n",
      "Wall time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = LGBMRegressor(random_state=1999)\n",
    "\n",
    "lgb.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lgb.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'mean_squared_log_error is : {error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(train_, test_):\n",
    "    df = pd.concat([train_, test_], axis = 0).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def split(df):\n",
    "    train_, test_ = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop=True)\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['source_+_dest'] = df.apply(lambda x: x['source'] + x['destination'], axis = 1)\n",
    "# It worked, but not logical so try later 1.6922603905441371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for Boosting\n",
    "def cross_val(regressor, train, test, features, name):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True,random_state = 1999)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels=False, duplicates='drop')\n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n================================Fold{index + 1}===================================')\n",
    "        \n",
    "        #### Train Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], train[target].iloc[trn_idx]\n",
    "        \n",
    "        #### Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], train[target].iloc[val_idx]\n",
    "        \n",
    "        #### Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "#         if name != 'cat':\n",
    "#             #### Scaling Data ####\n",
    "#             scaler = StandardScaler()\n",
    "#             _ = scaler.fit(X_trn)\n",
    "#             X_trn = scaler.transform(X_trn)\n",
    "#             X_val = scaler.transform(X_val)\n",
    "#             X_test = scaler.transform(X_test)\n",
    "        \n",
    "        ############ Fitting #############\n",
    "        _ = regressor.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 50, verbose = 100)\n",
    "        \n",
    "        ############ Predicting #############\n",
    "        val_preds = np.abs(regressor.predict(X_val))\n",
    "        test_preds = np.abs(regressor.predict(X_test))\n",
    "        \n",
    "        error = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        print(f'\\n Root Log Mean Squared Error for Validation set is : {error}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    total_error = np.sqrt(mean_squared_error(target_col, oofs))\n",
    "    print(f'\\n\\Root Log Mean Squared Error for oofs is {total_error}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>cab_provider</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>distance</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>fare</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-26 03:40:46.318</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-26 03:40:46.319</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-26 03:40:46.320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-26 03:40:46.320</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-26 03:40:46.320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time_stamp  cab_provider  source  destination  distance  \\\n",
       "0 2018-11-26 03:40:46.318             0       7            1      3.03   \n",
       "1 2018-11-26 03:40:46.319             1      10            1      1.30   \n",
       "2 2018-11-26 03:40:46.320             1       1            2      2.71   \n",
       "3 2018-11-26 03:40:46.320             0       5            3      2.43   \n",
       "4 2018-11-26 03:40:46.320             1       1            2      2.71   \n",
       "\n",
       "   surge_multiplier  cab_type  fare  hour  minute  day  \n",
       "0               1.0         4  34.0     3      40   26  \n",
       "1               1.0         0  18.5     3      40   26  \n",
       "2               1.0         9  19.5     3      40   26  \n",
       "3               1.0         5  10.5     3      40   26  \n",
       "4               1.0        10  32.0     3      40   26  "
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = join(train_proc, test_proc)\n",
    "\n",
    "\n",
    "df['Cab_Count_Per_Days_Hour'] = df.groupby(['day', 'hour'])['source'].transform('count')\n",
    "df['hour_surge'] = df.groupby(['cab_type'])['distance'].transform('mean')\n",
    "\n",
    "train_feat, test_feat = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = join(train_feat, test_feat)\n",
    "\n",
    "\n",
    "\n",
    "# temp = df.groupby(['cab_provider']).agg({'distance':['mean','min', 'max'],\n",
    "#                                      'fare':['mean','sum', 'min', 'max'],\n",
    "#                                     })\n",
    "\n",
    "# temp.columns = ['cab_provider_'.join(x) for x in temp.columns]\n",
    "# df = pd.merge(df,temp,on=['cab_provider'],how='left')\n",
    "\n",
    "\n",
    "\n",
    "# temp = df.groupby(['source', 'destination']).agg({'distance':['count','mean','min', 'max'],\n",
    "#                                      'fare':['count','mean','sum', 'min', 'max'],\n",
    "#                                     })\n",
    "\n",
    "# temp.columns = ['source_destination_'.join(x) for x in temp.columns]\n",
    "# df = pd.merge(df,temp,on=['source', 'destination'],how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# temp = df.groupby(['cab_type']).agg({'distance':['mean','min', 'max'],\n",
    "#                                      'fare':['mean','sum', 'min', 'max'],\n",
    "#                                     })\n",
    "\n",
    "# temp.columns = ['cab_type_'.join(x) for x in temp.columns]\n",
    "# df = pd.merge(df,temp,on=['cab_type'],how='left')\n",
    "\n",
    "\n",
    "# train_feat, test_feat = split(df)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_feat.columns if col not in [target, time]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "[0]\tvalidation_0-rmse:13.13262\n",
      "[99]\tvalidation_0-rmse:1.70683\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.7068273599171762\n",
      "\n",
      "================================Fold2===================================\n",
      "[0]\tvalidation_0-rmse:13.08994\n",
      "[99]\tvalidation_0-rmse:1.65883\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6588337884451416\n",
      "\n",
      "================================Fold3===================================\n",
      "[0]\tvalidation_0-rmse:13.16666\n",
      "[99]\tvalidation_0-rmse:1.61752\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6173941940753123\n",
      "\n",
      "================================Fold4===================================\n",
      "[0]\tvalidation_0-rmse:13.08444\n",
      "[99]\tvalidation_0-rmse:1.60287\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6026512711259184\n",
      "\n",
      "================================Fold5===================================\n",
      "[0]\tvalidation_0-rmse:13.17432\n",
      "[99]\tvalidation_0-rmse:1.62781\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6278104472311594\n",
      "\n",
      "\\Root Log Mean Squared Error for oofs is 1.6431196610249696\n",
      "Wall time: 6.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBRegressor(random_state = 1999)\n",
    "xgb_oofs, xgb_preds = cross_val(xgb, train_feat, test_feat, features, 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cab_provider': 1.2506357,\n",
       " 'source': 0.2194538,\n",
       " 'destination': 0.26532236,\n",
       " 'distance': 5.1875668,\n",
       " 'surge_multiplier': 8.329879,\n",
       " 'cab_type': 67.314705,\n",
       " 'hour': 0.09740815,\n",
       " 'minute': 0.1005377,\n",
       " 'day': 0.16820502,\n",
       " 'Cab_Count_Per_Days_Hour': 0.09272708,\n",
       " 'hour_surge': 16.973555}"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(features, xgb.feature_importances_*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note Downs:\n",
    "\n",
    "### trn_tst_split :\n",
    "        1. XGB: 1.70\n",
    "        2. LGB: 1.77\n",
    "### cross_val : \n",
    "        1. XGB: 1.64\n",
    "        2. LGB: 1.71\n",
    "\n",
    "### Features With Cross Val:\n",
    "        1. 'Cab_Count_Per_Days_Hour' : 1.6391\n",
    "        2. 'Cab_count_per_source_dest : 1.6479069412565543\n",
    "        3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
