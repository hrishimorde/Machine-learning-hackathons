{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + \"\\\\TRAIN.csv\")\n",
    "test = pd.read_csv(path + \"\\\\TEST.csv\")\n",
    "ss = pd.read_csv(path + \"\\\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_stamp'] = pd.to_datetime(df['time_stamp'], unit = 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('index', inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "le = LabelEncoder()\n",
    "sl = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hour\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.hour\n",
    "df[\"year\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.year\n",
    "df[\"minute\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.minute\n",
    "df[\"day\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.day\n",
    "df[\"dayofweek\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.dayofweek\n",
    "df[\"month\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.month\n",
    "df[\"weekday\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'fare'\n",
    "time = 'time_stamp'\n",
    "time_feats = ['hour', 'year', 'minute', 'day','dayofweek', 'month', 'weekday']\n",
    "\n",
    "features = [col for col in df.columns if col not in [target, time]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['cab_provider',\n",
    " 'source',\n",
    " 'destination',\n",
    " 'distance',\n",
    " 'surge_multiplier',\n",
    " 'cab_type',\n",
    " 'hour',\n",
    " 'year',\n",
    " 'minute',\n",
    " 'day',\n",
    " 'dayofweek',\n",
    " 'month',\n",
    " 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['cab_provider', 'source','destination', 'cab_type']\n",
    "\n",
    "df[label_cols] = df[label_cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc, test_proc = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "trn, val = train_test_split(train_proc, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test_proc[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,BaggingRegressor, StackingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 1.7691670385560418\n",
      "Wall time: 646 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = LGBMRegressor(random_state=1999)\n",
    "\n",
    "lgb.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lgb.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'mean_squared_log_error is : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error is : 1.7691670385560418\n",
      "Wall time: 439 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = LGBMRegressor(random_state=1999)\n",
    "\n",
    "lgb.fit(X_trn, y_trn)\n",
    "\n",
    "preds = lgb.predict(X_val)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'mean_squared_log_error is : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb = XGBRegressor(random_state = 1999)\n",
    "\n",
    "xgb.fit(train_proc[features], train_proc[target])\n",
    "preds = xgb.predict(X_test)\n",
    "preds = np.abs(preds)\n",
    "\n",
    "#error = np.sqrt(mean_squared_error(y_val, preds))\n",
    "\n",
    "#print(f'mean_squared_log_error is : {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for Boosting\n",
    "def cross_val(regressor, train, test, features, name):\n",
    "    N_splits = 7\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True,random_state = 1999)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels=False, duplicates='drop')\n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n================================Fold{index + 1}===================================')\n",
    "        \n",
    "        #### Train Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], train[target].iloc[trn_idx]\n",
    "        \n",
    "        #### Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], train[target].iloc[val_idx]\n",
    "        \n",
    "        #### Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "        if name != 'cat':\n",
    "            #### Scaling Data ####\n",
    "            scaler = StandardScaler()\n",
    "            _ = scaler.fit(X_trn)\n",
    "            X_trn = scaler.transform(X_trn)\n",
    "            X_val = scaler.transform(X_val)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        \n",
    "        ############ Fitting #############\n",
    "        _ = regressor.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 50, verbose = False)\n",
    "        \n",
    "        ############ Predicting #############\n",
    "        val_preds = np.abs(regressor.predict(X_val))\n",
    "        test_preds = np.abs(regressor.predict(X_test))\n",
    "        \n",
    "        error = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "        print(f'\\n Root Log Mean Squared Error for Validation set is : {error}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    total_error = np.sqrt(mean_squared_error(target_col, oofs))\n",
    "    print(f'\\n\\Root Log Mean Squared Error for oofs is {total_error}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================Fold1===================================\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.7355348565691844\n",
      "\n",
      "================================Fold2===================================\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.632135031440744\n",
      "\n",
      "================================Fold3===================================\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6719615570709805\n",
      "\n",
      "================================Fold4===================================\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6074971791499562\n",
      "\n",
      "================================Fold5===================================\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6071691541411763\n",
      "\n",
      "================================Fold6===================================\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.6276715167984774\n",
      "\n",
      "================================Fold7===================================\n",
      "\n",
      " Root Log Mean Squared Error for Validation set is : 1.598347532950827\n",
      "\n",
      "\\Root Log Mean Squared Error for oofs is 1.6406655134246648\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_oofs, xgb_preds = cross_val(xgb, train_proc, test_proc, features, 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in range(25000)]\n",
    "d = list(zip(index, xgb_preds))\n",
    "ss = pd.DataFrame(d, columns=['index', target])\n",
    "\n",
    "\n",
    "ss.to_csv(path + \"\\\\basline_xgb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weekday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dayofweek'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"week\"] = pd.to_datetime(df.time_stamp, format=\"%Y-%m-%d\").dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 41, 43, 49, 55,  3, 13, 14, 17, 28, 29, 36, 50, 15, 16, 19, 20,\n",
       "       21, 22, 23, 24, 25, 26, 27, 30, 11, 18, 38, 46, 34,  5,  8, 32, 35,\n",
       "       44, 47, 53, 56, 59,  2, 42, 45, 48, 51, 54, 57,  0,  6,  9, 12, 33,\n",
       "       39, 58, 31, 37,  1], dtype=int64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
