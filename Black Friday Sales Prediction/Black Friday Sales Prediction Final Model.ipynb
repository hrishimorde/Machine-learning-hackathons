{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='dark')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\sunil\\Projects\\Analytics vidya\\Black Friday Sales Prediction\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\sunil\\Projects\\Analytics vidya\\Black Friday Sales Prediction\\test.csv\")\n",
    "sample_sub = pd.read_csv(r\"C:\\Users\\sunil\\Projects\\Analytics vidya\\Black Friday Sales Prediction\\sample_submission_V9Inaty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(783667, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train, test], axis = 0).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783662</th>\n",
       "      <td>1006036</td>\n",
       "      <td>P00118942</td>\n",
       "      <td>F</td>\n",
       "      <td>26-35</td>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783663</th>\n",
       "      <td>1006036</td>\n",
       "      <td>P00254642</td>\n",
       "      <td>F</td>\n",
       "      <td>26-35</td>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783664</th>\n",
       "      <td>1006036</td>\n",
       "      <td>P00031842</td>\n",
       "      <td>F</td>\n",
       "      <td>26-35</td>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783665</th>\n",
       "      <td>1006037</td>\n",
       "      <td>P00124742</td>\n",
       "      <td>F</td>\n",
       "      <td>46-50</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783666</th>\n",
       "      <td>1006039</td>\n",
       "      <td>P00316642</td>\n",
       "      <td>F</td>\n",
       "      <td>46-50</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783667 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
       "0       1000001  P00069042      F   0-17          10             A   \n",
       "1       1000001  P00248942      F   0-17          10             A   \n",
       "2       1000001  P00087842      F   0-17          10             A   \n",
       "3       1000001  P00085442      F   0-17          10             A   \n",
       "4       1000002  P00285442      M    55+          16             C   \n",
       "...         ...        ...    ...    ...         ...           ...   \n",
       "783662  1006036  P00118942      F  26-35          15             B   \n",
       "783663  1006036  P00254642      F  26-35          15             B   \n",
       "783664  1006036  P00031842      F  26-35          15             B   \n",
       "783665  1006037  P00124742      F  46-50           1             C   \n",
       "783666  1006039  P00316642      F  46-50           0             B   \n",
       "\n",
       "       Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                               2               0                   3   \n",
       "1                               2               0                   1   \n",
       "2                               2               0                  12   \n",
       "3                               2               0                  12   \n",
       "4                              4+               0                   8   \n",
       "...                           ...             ...                 ...   \n",
       "783662                         4+               1                   8   \n",
       "783663                         4+               1                   5   \n",
       "783664                         4+               1                   1   \n",
       "783665                         4+               0                  10   \n",
       "783666                         4+               1                   4   \n",
       "\n",
       "        Product_Category_2  Product_Category_3  Purchase  \n",
       "0                      NaN                 NaN    8370.0  \n",
       "1                      6.0                14.0   15200.0  \n",
       "2                      NaN                 NaN    1422.0  \n",
       "3                     14.0                 NaN    1057.0  \n",
       "4                      NaN                 NaN    7969.0  \n",
       "...                    ...                 ...       ...  \n",
       "783662                 NaN                 NaN       NaN  \n",
       "783663                 8.0                 NaN       NaN  \n",
       "783664                 5.0                12.0       NaN  \n",
       "783665                16.0                 NaN       NaN  \n",
       "783666                 5.0                 NaN       NaN  \n",
       "\n",
       "[783667 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace( { 'M' : 1, 'F' : 0}, inplace=True)\n",
    "df['Age'].replace( {'0-17': 0, '18-25':1, '26-35':2, '36-45': 3, '46-50': 4, '51-55': 5, '55+': 6}, inplace=True)\n",
    "df['Stay_In_Current_City_Years'].replace( {'0': 0, '1': 1, '2': 2, '3': 3, '4+': 4}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "##### User_ID\n",
    "df['User_ID'] = df['User_ID'] - 1000000\n",
    "df['User_ID'] = le.fit_transform(df['User_ID'])\n",
    "\n",
    "##### Product_ID\n",
    "df['Product_ID'] = df['Product_ID'].str.replace('P00', '')\n",
    "df['Product_ID'] = le.fit_transform(df['Product_ID'])\n",
    "\n",
    "##### City Category\n",
    "df['City_Category'] = le.fit_transform(df['City_Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Datatype\n",
    "\n",
    "df['User_ID'] = df['User_ID'].astype('int16')\n",
    "df['Product_ID'] = df['Product_ID'].astype('int16')\n",
    "df['Gender'] = df['Gender'].astype('uint8')\n",
    "df['Age'] = df['Age'].astype('uint8')\n",
    "df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].astype('uint8')\n",
    "df['Marital_Status'] = df['Marital_Status'].astype('uint8')\n",
    "df['Product_Category_1'] = df['Product_Category_1'].astype('int8')\n",
    "df['Product_Category_2'] = df['Product_Category_2'].astype('int16')\n",
    "df['Product_Category_3'] = df['Product_Category_3'].astype('int16')\n",
    "df['Occupation'] = df['Product_Category_3'].astype('int8')\n",
    "\n",
    "\n",
    "\n",
    "df['Purchase'] = df[\"Purchase\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc, test_proc = df[:train.shape[0]], df[train.shape[0]:].reset_index(drop = True)\n",
    "\n",
    "target = 'Purchase'\n",
    "\n",
    "features = [col for col in train_proc.columns if col not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train_proc, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test_proc[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting_cross_val(regressor, train, test, features, name):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels = False, duplicates = 'drop')\n",
    "    \n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n=========================Fold{index+1}============================')\n",
    "        \n",
    "        ####### Getting Train, Validation and Test sets.\n",
    "        \n",
    "        ## Training Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], target_col.iloc[trn_idx]\n",
    "        \n",
    "        ## Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], target_col.iloc[val_idx]\n",
    "        \n",
    "        ## Test Set\n",
    "        X_test = test[features]\n",
    "        \n",
    "        if name != 'cat':\n",
    "            ###### Scaling Data ######\n",
    "            scaler = StandardScaler()\n",
    "            _ = scaler.fit(X_trn)\n",
    "\n",
    "            X_trn = scaler.transform(X_trn)\n",
    "            X_val = scaler.transform(X_val)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        ############ Fitting And Predicting #############\n",
    "        _ = regressor.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 50, verbose = False)\n",
    "        \n",
    "        ## Predicting\n",
    "        val_preds = regressor.predict(X_val)\n",
    "        test_preds = regressor.predict(X_test)\n",
    "        \n",
    "        fold_score = np.sqrt( mean_squared_error(y_val, val_preds))\n",
    "        print(f'\\n RMSE score for Validation set is : {fold_score}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    oofs_score = np.sqrt( mean_squared_error(target_col, oofs))\n",
    "    print(f'\\n\\nRMSE score for oofs is {oofs_score}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(df, column_list):\n",
    "    for col in column_list:\n",
    "        train_proc[col] = df[: train.shape[0]][col].reset_index(drop = True)\n",
    "        test_proc[col] = df[train_proc.shape[0]:][col].reset_index(drop = True)\n",
    "        features = [col for col in train_proc.columns if col not in [target]]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Features from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does user belongs to working class or not\n",
    "df['is_working'] = df['Age'].apply(lambda x: 1 if (x!='0-17' and x!='55+' and x!='51-55' and x!='46-50') else 0)\n",
    "\n",
    "# Does particular product_cat_1 is popular or not\n",
    "df['is_popular'] = df['Product_Category_1'].apply(lambda x: 1 if x in [1,5,8] else 0)\n",
    "\n",
    "col_ls = ['is_working', 'is_popular', ]\n",
    "\n",
    "features = helper(df, col_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_prod_ls = list(set(df[ df['Gender'] == 'F']['Product_ID'].to_list()))\n",
    "male_prod_ls = list(set(df[ df['Gender'] == 'M']['Product_ID'].to_list()))\n",
    "\n",
    "female_products = list(np.setdiff1d(female_prod_ls, male_prod_ls))\n",
    "male_products = list(np.setdiff1d( male_prod_ls, female_prod_ls))\n",
    "\n",
    "# Does only females are buying particluar product_id\n",
    "df['is_female_product'] = df['Product_ID'].apply(lambda x: 1 if x in female_products else 0)\n",
    "\n",
    "# Does only males are buying particluar product_id\n",
    "df['is_male_product'] = df['Product_ID'].apply(lambda x: 1 if x in male_products else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ls = ['is_female_product', 'is_male_product']\n",
    "\n",
    "features = helper(df, col_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Grouping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique product id's per user\n",
    "df['Users_unique_products'] = df.groupby('User_ID')['Product_ID'].transform('nunique')\n",
    "\n",
    "# Number of unique users per product_id\n",
    "df['Products_unique_users'] = df.groupby('Product_ID')['User_ID'].transform('nunique')\n",
    "\n",
    "# Number of unique products per city\n",
    "df['Citys_unique_products'] = df.groupby('City_Category')['Product_ID'].transform('nunique')\n",
    "\n",
    "# Number of unique products per Age_group\n",
    "df['Age_unique_products'] = df.groupby('Age')['Product_ID'].transform('nunique')\n",
    "\n",
    "# Number of unique Users per Age_group\n",
    "df['Age_unique_users'] = df.groupby('Age')['User_ID'].transform('nunique')\n",
    "\n",
    "# Number of unique Products per Occupation\n",
    "df['Occupation_unique_products'] = df.groupby('Occupation')['Product_ID'].transform('nunique')\n",
    "\n",
    "# Number of unique Users per Occupation\n",
    "df['Occupation_unique_users'] = df.groupby('Occupation')['User_ID'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Users_Mean_Purchase'] = df.groupby('User_ID')['Purchase'].transform('mean')\n",
    "df['Users_Median_Purchase'] = df.groupby('User_ID')['Purchase'].transform('median')\n",
    "#df['Products_Mean_Purchase'] = df.groupby('Product_ID')['Purchase'].transform('mean')\n",
    "#df['Products_Median_Purchase'] = df.groupby('Product_ID')['Purchase'].transform('median')\n",
    "\n",
    "df['Product_Category_1_Mean_Purchase'] = df.groupby('Product_Category_1')['Purchase'].transform('mean')\n",
    "df['Product_Category_1_Median_Purchase'] = df.groupby('Product_Category_1')['Purchase'].transform('median')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ls = ['Users_unique_products', 'Products_unique_users', 'Citys_unique_products', 'Age_unique_products', 'Age_unique_users',\n",
    " 'Occupation_unique_products', 'Occupation_unique_users','Users_Mean_Purchase', 'Users_Median_Purchase',\n",
    "         'Product_Category_1_Mean_Purchase', 'Product_Category_1_Median_Purchase']\n",
    "\n",
    "features = helper(df, col_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Users_Total_Purchase'] = df.groupby('User_ID')['Purchase'].transform('sum')\n",
    "#df['Products_Total_Purchase'] = df.groupby('Product_ID')['Purchase'].transform('sum')\n",
    "\n",
    "df['Users_Minimum_Purchase'] = df.groupby('User_ID')['Purchase'].transform('min')\n",
    "#df['Products_Minimum_Purchase'] = df.groupby('Product_ID')['Purchase'].transform('min')\n",
    "\n",
    "df['Users_Maximum_Purchase'] = df.groupby('User_ID')['Purchase'].transform('max')\n",
    "#df['Products_Maximum_Purchase'] = df.groupby('Product_ID')['Purchase'].transform('max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ls = ['Users_Total_Purchase', 'Users_Minimum_Purchase', \n",
    "         'Users_Maximum_Purchase']\n",
    "\n",
    "features = helper(df, col_ls)\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Products_Mean_Purchase and Products_Median_Purchase by Product_Category_1_Mean_Purchase and Product_Category_1_Median_Purchase respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_proc.loc[ test_proc['Products_Mean_Purchase'].isna(), 'Products_Mean_Purchase'] = test_proc[ test_proc['Products_Mean_Purchase'].isna()]['Product_Category_1_Mean_Purchase'].apply(lambda x: x)\n",
    "\n",
    "#test_proc.loc[ test_proc['Products_Median_Purchase'].isna(), 'Products_Median_Purchase'] = test_proc[ test_proc['Products_Median_Purchase'].isna()]['Product_Category_1_Median_Purchase'].apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_proc.loc[ test_proc['Products_Minimum_Purchase'].isna(), 'Products_Minimum_Purchase'] = test_proc[ test_proc['Products_Minimum_Purchase'].isna()]['Products_Total_Purchase'].apply(lambda x: x)\n",
    "\n",
    "#test_proc.loc[ test_proc['Products_Maximum_Purchase'].isna(), 'Products_Maximum_Purchase'] = test_proc[ test_proc['Products_Maximum_Purchase'].isna()]['Products_Total_Purchase'].apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Changing Datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8_cols = ['is_working', 'is_popular', 'is_female_product', 'is_male_product', 'City_Category', ]\n",
    "\n",
    "int_8_cols = ['Product_Category_2', 'Product_Category_3']\n",
    "\n",
    "int16_cols = ['Users_unique_products', 'Products_unique_users', 'Citys_unique_products', 'Age_unique_products', 'Age_unique_users',\n",
    "             'Occupation_unique_products', 'Occupation_unique_users', 'Users_Mean_Purchase', 'Users_Median_Purchase',\n",
    "            'Product_Category_1_Mean_Purchase', 'Product_Category_1_Median_Purchase', \n",
    "             'Users_Total_Purchase', 'Users_Minimum_Purchase', \n",
    "         'Users_Maximum_Purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc[uint8_cols] = train_proc[uint8_cols].astype('uint8')\n",
    "test_proc[uint8_cols] = test_proc[uint8_cols].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc[int_8_cols] = train_proc[int_8_cols].astype('int8')\n",
    "test_proc[int_8_cols] = test_proc[int_8_cols].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc[int16_cols] = train_proc[int16_cols].astype('int16')\n",
    "test_proc[int16_cols] = test_proc[int16_cols].astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Splitting into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "traget = 'Purchase'\n",
    "\n",
    "features = [col for col in train_proc.columns if col not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train_proc, test_size = 0.2, random_state = 1999)\n",
    "\n",
    "##### Input for model\n",
    "X_trn, X_val = trn[features], val[features]\n",
    "\n",
    "##### Target column\n",
    "y_trn, y_val = trn[target], val[target]\n",
    "\n",
    "##### Features for test data that we will be predicting\n",
    "X_test = test_proc[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score is: 2557.4681108774544\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = LGBMRegressor(random_state=1999)\n",
    "lgb.fit(X_trn, y_trn)\n",
    "preds = lgb.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'RMSE score is: {rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 22:15:23,869] A new study created in memory with name: no-name-b5b05bc8-405f-45ff-aa73-fc287e8f4231\n",
      "[I 2020-10-08 22:15:29,290] Trial 0 finished with value: 2587.8838894652417 and parameters: {'max_depth': 14, 'n_estimators': 48, 'learning_rate': 0.7436704297351775, 'num_leaves': 4933, 'colsample_bytree': 0.7863564940982054, 'min_child_samples': 106, 'reg_alpha': 10, 'reg_lambda': 4}. Best is trial 0 with value: 2587.8838894652417.\n",
      "[I 2020-10-08 22:16:28,195] Trial 1 finished with value: 2786.042032412337 and parameters: {'max_depth': 23, 'n_estimators': 243, 'learning_rate': 0.49382849013642327, 'num_leaves': 3470, 'colsample_bytree': 0.40675321506062223, 'min_child_samples': 42, 'reg_alpha': 8, 'reg_lambda': 9}. Best is trial 0 with value: 2587.8838894652417.\n",
      "[I 2020-10-08 22:16:44,267] Trial 2 finished with value: 2774.001957023837 and parameters: {'max_depth': 19, 'n_estimators': 166, 'learning_rate': 0.8524708871836397, 'num_leaves': 2165, 'colsample_bytree': 0.39459323187243844, 'min_child_samples': 200, 'reg_alpha': 1, 'reg_lambda': 3}. Best is trial 0 with value: 2587.8838894652417.\n",
      "[I 2020-10-08 22:16:52,775] Trial 3 finished with value: 2487.317763599482 and parameters: {'max_depth': 5, 'n_estimators': 473, 'learning_rate': 0.8208196767816798, 'num_leaves': 799, 'colsample_bytree': 0.7244233410291644, 'min_child_samples': 145, 'reg_alpha': 8, 'reg_lambda': 1}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:16:56,487] Trial 4 finished with value: 2551.3060649819795 and parameters: {'max_depth': 3, 'n_estimators': 266, 'learning_rate': 0.5836359065041096, 'num_leaves': 546, 'colsample_bytree': 0.5174786574000574, 'min_child_samples': 154, 'reg_alpha': 4, 'reg_lambda': 3}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:17:01,875] Trial 5 finished with value: 2550.4546200118143 and parameters: {'max_depth': 25, 'n_estimators': 29, 'learning_rate': 0.6115905539817836, 'num_leaves': 2178, 'colsample_bytree': 0.3593128062345713, 'min_child_samples': 136, 'reg_alpha': 7, 'reg_lambda': 9}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:17:38,510] Trial 6 finished with value: 3154.934988745777 and parameters: {'max_depth': 22, 'n_estimators': 274, 'learning_rate': 0.9493732706631618, 'num_leaves': 1643, 'colsample_bytree': 0.45995999192898207, 'min_child_samples': 34, 'reg_alpha': 9, 'reg_lambda': 2}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:17:44,177] Trial 7 finished with value: 2565.046852393036 and parameters: {'max_depth': 3, 'n_estimators': 488, 'learning_rate': 0.15420292446634287, 'num_leaves': 3944, 'colsample_bytree': 0.6365102956945276, 'min_child_samples': 177, 'reg_alpha': 3, 'reg_lambda': 1}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:17:53,323] Trial 8 finished with value: 2504.5698729272126 and parameters: {'max_depth': 16, 'n_estimators': 100, 'learning_rate': 0.42733969384836035, 'num_leaves': 2683, 'colsample_bytree': 0.13074034117818778, 'min_child_samples': 71, 'reg_alpha': 7, 'reg_lambda': 5}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:18:04,603] Trial 9 finished with value: 2592.911215855105 and parameters: {'max_depth': 17, 'n_estimators': 128, 'learning_rate': 0.6715529862432075, 'num_leaves': 1206, 'colsample_bytree': 0.3026332820318257, 'min_child_samples': 146, 'reg_alpha': 5, 'reg_lambda': 4}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:18:14,223] Trial 10 finished with value: 2645.6588540933485 and parameters: {'max_depth': 9, 'n_estimators': 494, 'learning_rate': 0.957500434774104, 'num_leaves': 60, 'colsample_bytree': 0.8690157185708779, 'min_child_samples': 97, 'reg_alpha': 6, 'reg_lambda': 7}. Best is trial 3 with value: 2487.317763599482.\n",
      "[I 2020-10-08 22:18:22,734] Trial 11 finished with value: 2458.987583481605 and parameters: {'max_depth': 10, 'n_estimators': 363, 'learning_rate': 0.29805290403271123, 'num_leaves': 3179, 'colsample_bytree': 0.10913087880627068, 'min_child_samples': 73, 'reg_alpha': 8, 'reg_lambda': 6}. Best is trial 11 with value: 2458.987583481605.\n",
      "[I 2020-10-08 22:18:37,079] Trial 12 finished with value: 2441.578586462782 and parameters: {'max_depth': 9, 'n_estimators': 380, 'learning_rate': 0.25579387982346813, 'num_leaves': 3167, 'colsample_bytree': 0.6905512541698189, 'min_child_samples': 78, 'reg_alpha': 10, 'reg_lambda': 7}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:18:48,236] Trial 13 finished with value: 2455.171779682748 and parameters: {'max_depth': 10, 'n_estimators': 383, 'learning_rate': 0.22127949520793802, 'num_leaves': 3541, 'colsample_bytree': 0.11574674116208994, 'min_child_samples': 73, 'reg_alpha': 10, 'reg_lambda': 7}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:19:12,777] Trial 14 finished with value: 2460.5731920992635 and parameters: {'max_depth': 10, 'n_estimators': 382, 'learning_rate': 0.19724070898890084, 'num_leaves': 4482, 'colsample_bytree': 0.5953400251891563, 'min_child_samples': 8, 'reg_alpha': 10, 'reg_lambda': 7}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:19:38,848] Trial 15 finished with value: 2517.271589010491 and parameters: {'max_depth': 12, 'n_estimators': 403, 'learning_rate': 0.3381652607609078, 'num_leaves': 3985, 'colsample_bytree': 0.24885202566991588, 'min_child_samples': 62, 'reg_alpha': 10, 'reg_lambda': 10}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:19:49,045] Trial 16 finished with value: 2448.5045354782965 and parameters: {'max_depth': 7, 'n_estimators': 327, 'learning_rate': 0.12156632208484225, 'num_leaves': 2956, 'colsample_bytree': 0.8888012003550287, 'min_child_samples': 104, 'reg_alpha': 10, 'reg_lambda': 8}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:21:16,200] Trial 17 finished with value: 2490.119128999412 and parameters: {'max_depth': 30, 'n_estimators': 330, 'learning_rate': 0.10800830303923797, 'num_leaves': 2834, 'colsample_bytree': 0.8988810777259401, 'min_child_samples': 106, 'reg_alpha': 1, 'reg_lambda': 8}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:21:29,013] Trial 18 finished with value: 2445.267532693039 and parameters: {'max_depth': 7, 'n_estimators': 444, 'learning_rate': 0.35228776863856315, 'num_leaves': 1850, 'colsample_bytree': 0.7915001062656595, 'min_child_samples': 118, 'reg_alpha': 9, 'reg_lambda': 10}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:21:39,215] Trial 19 finished with value: 2446.7889660219807 and parameters: {'max_depth': 6, 'n_estimators': 447, 'learning_rate': 0.40336818321689505, 'num_leaves': 1800, 'colsample_bytree': 0.7397189850786133, 'min_child_samples': 123, 'reg_alpha': 9, 'reg_lambda': 10}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:22:11,199] Trial 20 finished with value: 2512.6928592736585 and parameters: {'max_depth': 14, 'n_estimators': 433, 'learning_rate': 0.2961198577562003, 'num_leaves': 2313, 'colsample_bytree': 0.6677838985828388, 'min_child_samples': 173, 'reg_alpha': 9, 'reg_lambda': 9}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:22:21,402] Trial 21 finished with value: 2454.740382103685 and parameters: {'max_depth': 7, 'n_estimators': 441, 'learning_rate': 0.4245260044081054, 'num_leaves': 1721, 'colsample_bytree': 0.790969279716009, 'min_child_samples': 125, 'reg_alpha': 9, 'reg_lambda': 10}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:22:25,943] Trial 22 finished with value: 2594.358337879161 and parameters: {'max_depth': 2, 'n_estimators': 443, 'learning_rate': 0.3956168378481447, 'num_leaves': 1697, 'colsample_bytree': 0.7964893293798977, 'min_child_samples': 127, 'reg_alpha': 7, 'reg_lambda': 10}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:22:32,290] Trial 23 finished with value: 2456.1409409919656 and parameters: {'max_depth': 6, 'n_estimators': 330, 'learning_rate': 0.47778791927643627, 'num_leaves': 1398, 'colsample_bytree': 0.7166788812847927, 'min_child_samples': 90, 'reg_alpha': 9, 'reg_lambda': 8}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:22:40,538] Trial 24 finished with value: 2460.9007651950856 and parameters: {'max_depth': 5, 'n_estimators': 496, 'learning_rate': 0.22669728560937472, 'num_leaves': 944, 'colsample_bytree': 0.5656448901252918, 'min_child_samples': 119, 'reg_alpha': 8, 'reg_lambda': 10}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:23:14,261] Trial 25 finished with value: 2579.674171834736 and parameters: {'max_depth': 13, 'n_estimators': 420, 'learning_rate': 0.3527963057594687, 'num_leaves': 2012, 'colsample_bytree': 0.7193185851363881, 'min_child_samples': 82, 'reg_alpha': 6, 'reg_lambda': 6}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:23:20,907] Trial 26 finished with value: 2473.2133084287043 and parameters: {'max_depth': 4, 'n_estimators': 464, 'learning_rate': 0.5042364809075153, 'num_leaves': 3275, 'colsample_bytree': 0.836125039082614, 'min_child_samples': 53, 'reg_alpha': 9, 'reg_lambda': 9}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:23:27,381] Trial 27 finished with value: 2445.308858713611 and parameters: {'max_depth': 8, 'n_estimators': 207, 'learning_rate': 0.28054246025457824, 'num_leaves': 169, 'colsample_bytree': 0.6519731490065532, 'min_child_samples': 163, 'reg_alpha': 10, 'reg_lambda': 8}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:23:34,419] Trial 28 finished with value: 2442.012858964962 and parameters: {'max_depth': 8, 'n_estimators': 204, 'learning_rate': 0.27105724449674495, 'num_leaves': 187, 'colsample_bytree': 0.654352831189736, 'min_child_samples': 200, 'reg_alpha': 10, 'reg_lambda': 8}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:23:52,718] Trial 29 finished with value: 2485.4690640518656 and parameters: {'max_depth': 12, 'n_estimators': 187, 'learning_rate': 0.2455819253109758, 'num_leaves': 4808, 'colsample_bytree': 0.5510983544616177, 'min_child_samples': 17, 'reg_alpha': 10, 'reg_lambda': 5}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:23:58,275] Trial 30 finished with value: 2451.4061458702 and parameters: {'max_depth': 12, 'n_estimators': 75, 'learning_rate': 0.1540074667579104, 'num_leaves': 370, 'colsample_bytree': 0.8238537900839947, 'min_child_samples': 199, 'reg_alpha': 2, 'reg_lambda': 7}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:24:06,080] Trial 31 finished with value: 2443.133059869332 and parameters: {'max_depth': 8, 'n_estimators': 224, 'learning_rate': 0.2834986353800022, 'num_leaves': 126, 'colsample_bytree': 0.6594651940360712, 'min_child_samples': 181, 'reg_alpha': 10, 'reg_lambda': 8}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:24:13,019] Trial 32 finished with value: 2442.500017296141 and parameters: {'max_depth': 8, 'n_estimators': 232, 'learning_rate': 0.33783405877027123, 'num_leaves': 679, 'colsample_bytree': 0.6125107511661525, 'min_child_samples': 186, 'reg_alpha': 10, 'reg_lambda': 6}. Best is trial 12 with value: 2441.578586462782.\n",
      "[I 2020-10-08 22:24:22,266] Trial 33 finished with value: 2435.9369034548904 and parameters: {'max_depth': 9, 'n_estimators': 232, 'learning_rate': 0.18373401603524575, 'num_leaves': 547, 'colsample_bytree': 0.6045116128226518, 'min_child_samples': 191, 'reg_alpha': 10, 'reg_lambda': 6}. Best is trial 33 with value: 2435.9369034548904.\n",
      "[I 2020-10-08 22:24:29,814] Trial 34 finished with value: 2436.503816095773 and parameters: {'max_depth': 11, 'n_estimators': 163, 'learning_rate': 0.18833931049988872, 'num_leaves': 746, 'colsample_bytree': 0.4716490147976381, 'min_child_samples': 199, 'reg_alpha': 8, 'reg_lambda': 6}. Best is trial 33 with value: 2435.9369034548904.\n",
      "[I 2020-10-08 22:24:41,204] Trial 35 finished with value: 2432.192368623289 and parameters: {'max_depth': 15, 'n_estimators': 149, 'learning_rate': 0.18050690261002905, 'num_leaves': 936, 'colsample_bytree': 0.4537061351052922, 'min_child_samples': 195, 'reg_alpha': 8, 'reg_lambda': 5}. Best is trial 35 with value: 2432.192368623289.\n",
      "[I 2020-10-08 22:24:56,348] Trial 36 finished with value: 2427.841054350778 and parameters: {'max_depth': 19, 'n_estimators': 148, 'learning_rate': 0.15441064375544633, 'num_leaves': 1075, 'colsample_bytree': 0.47179940627032607, 'min_child_samples': 195, 'reg_alpha': 8, 'reg_lambda': 5}. Best is trial 36 with value: 2427.841054350778.\n",
      "[I 2020-10-08 22:25:10,787] Trial 37 finished with value: 2435.5560891195173 and parameters: {'max_depth': 20, 'n_estimators': 146, 'learning_rate': 0.1798260812442875, 'num_leaves': 1021, 'colsample_bytree': 0.47316638839019465, 'min_child_samples': 191, 'reg_alpha': 7, 'reg_lambda': 4}. Best is trial 36 with value: 2427.841054350778.\n",
      "[I 2020-10-08 22:25:25,183] Trial 38 finished with value: 2422.378370778711 and parameters: {'max_depth': 20, 'n_estimators': 134, 'learning_rate': 0.10262595510667413, 'num_leaves': 1019, 'colsample_bytree': 0.42232012384866296, 'min_child_samples': 189, 'reg_alpha': 7, 'reg_lambda': 4}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:25:39,189] Trial 39 finished with value: 2425.8109424886593 and parameters: {'max_depth': 20, 'n_estimators': 130, 'learning_rate': 0.14870545872122706, 'num_leaves': 1142, 'colsample_bytree': 0.4288981212615482, 'min_child_samples': 162, 'reg_alpha': 7, 'reg_lambda': 4}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:25:40,235] Trial 40 finished with value: 4488.326832156967 and parameters: {'max_depth': 23, 'n_estimators': 2, 'learning_rate': 0.10264727073639332, 'num_leaves': 1388, 'colsample_bytree': 0.40004080886217114, 'min_child_samples': 161, 'reg_alpha': 6, 'reg_lambda': 3}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:25:53,737] Trial 41 finished with value: 2423.534366539217 and parameters: {'max_depth': 20, 'n_estimators': 133, 'learning_rate': 0.1455941495334232, 'num_leaves': 1035, 'colsample_bytree': 0.4395920526598471, 'min_child_samples': 171, 'reg_alpha': 7, 'reg_lambda': 4}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:26:05,895] Trial 42 finished with value: 2430.124588276845 and parameters: {'max_depth': 19, 'n_estimators': 110, 'learning_rate': 0.13473174294495205, 'num_leaves': 1160, 'colsample_bytree': 0.36109897138598845, 'min_child_samples': 170, 'reg_alpha': 5, 'reg_lambda': 3}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:26:17,460] Trial 43 finished with value: 2436.9206660764603 and parameters: {'max_depth': 19, 'n_estimators': 95, 'learning_rate': 0.16233923814088913, 'num_leaves': 1265, 'colsample_bytree': 0.3443315976522769, 'min_child_samples': 172, 'reg_alpha': 5, 'reg_lambda': 3}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:26:22,581] Trial 44 finished with value: 2529.534279481767 and parameters: {'max_depth': 25, 'n_estimators': 45, 'learning_rate': 0.10814566407226485, 'num_leaves': 1166, 'colsample_bytree': 0.28803460840417694, 'min_child_samples': 145, 'reg_alpha': 5, 'reg_lambda': 2}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:26:37,455] Trial 45 finished with value: 2425.989593435444 and parameters: {'max_depth': 18, 'n_estimators': 127, 'learning_rate': 0.13301078056982127, 'num_leaves': 1451, 'colsample_bytree': 0.4290315593244872, 'min_child_samples': 162, 'reg_alpha': 4, 'reg_lambda': 4}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:26:45,271] Trial 46 finished with value: 2657.7160884370965 and parameters: {'max_depth': 17, 'n_estimators': 68, 'learning_rate': 0.8278054985603419, 'num_leaves': 1494, 'colsample_bytree': 0.5105155394440377, 'min_child_samples': 161, 'reg_alpha': 4, 'reg_lambda': 4}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:26:51,443] Trial 47 finished with value: 2673.0949442250135 and parameters: {'max_depth': 21, 'n_estimators': 121, 'learning_rate': 0.9053227518186364, 'num_leaves': 397, 'colsample_bytree': 0.4188624011334488, 'min_child_samples': 152, 'reg_alpha': 6, 'reg_lambda': 5}. Best is trial 38 with value: 2422.378370778711.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 22:27:22,842] Trial 48 finished with value: 2427.0009325318297 and parameters: {'max_depth': 24, 'n_estimators': 185, 'learning_rate': 0.10119675514520346, 'num_leaves': 2501, 'colsample_bytree': 0.4259991748714801, 'min_child_samples': 137, 'reg_alpha': 7, 'reg_lambda': 4}. Best is trial 38 with value: 2422.378370778711.\n",
      "[I 2020-10-08 22:27:44,359] Trial 49 finished with value: 2677.106171022139 and parameters: {'max_depth': 26, 'n_estimators': 182, 'learning_rate': 0.750886614080417, 'num_leaves': 2505, 'colsample_bytree': 0.19168932339557335, 'min_child_samples': 147, 'reg_alpha': 7, 'reg_lambda': 2}. Best is trial 38 with value: 2422.378370778711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized LightGBM roc_auc_score 2422.405397386889\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def create_model(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.1, 1)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 0.9),\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n",
    "    reg_alpha = trial.suggest_int(\"reg_alpha\", 1, 10)\n",
    "    reg_lambda = trial.suggest_int(\"reg_lambda\", 1, 10)\n",
    "    model = LGBMRegressor(\n",
    "        learning_rate=learning_rate, \n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth,\n",
    "        num_leaves=num_leaves,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        min_child_samples=min_child_samples,\n",
    "        random_state=1999\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sampler = TPESampler(seed=0)\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_trn, y_trn)\n",
    "    preds = model.predict(X_val)\n",
    "    score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "lgb_params = study.best_params\n",
    "lgb_params['random_state'] = 0\n",
    "lgb = LGBMRegressor(**lgb_params)\n",
    "lgb.fit(X_trn, y_trn)\n",
    "preds = lgb.predict(X_val)\n",
    "print('Optimized LightGBM roc_auc_score', np.sqrt(mean_squared_error(y_val, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score is: 2422.405397386889\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = lgb\n",
    "lgb.fit(X_trn, y_trn)\n",
    "preds = lgb.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'RMSE score is: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Fold1============================\n",
      "\n",
      " RMSE score for Validation set is : 2429.030850296995\n",
      "\n",
      "=========================Fold2============================\n",
      "\n",
      " RMSE score for Validation set is : 2431.0283203052\n",
      "\n",
      "=========================Fold3============================\n",
      "\n",
      " RMSE score for Validation set is : 2420.0737577032637\n",
      "\n",
      "=========================Fold4============================\n",
      "\n",
      " RMSE score for Validation set is : 2420.836016872785\n",
      "\n",
      "=========================Fold5============================\n",
      "\n",
      " RMSE score for Validation set is : 2432.1053030762155\n",
      "\n",
      "\n",
      "RMSE score for oofs is 2426.620275074255\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_fe_oofs, lgb_fe_preds = boosting_cross_val(lgb, train_proc, test_proc, features, 'lgb')\n",
    "sample_sub['Purchase'] = lgb_fe_preds\n",
    "sample_sub.to_csv(r\"D:\\Data Science\\Projects\\Analytics vidya\\Black Friday Sales Prediction\\final\\LGBM_Tuned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score is: 2500.1502293901635\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBRegressor(random_state=1999)\n",
    "xgb.fit(X_trn, y_trn)\n",
    "preds = xgb.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'RMSE score is: {rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 22:30:00,772] A new study created in memory with name: no-name-500674f5-aa45-430c-a308-125b581f03e9\n",
      "[I 2020-10-08 22:30:22,928] Trial 0 finished with value: 2813.0052598074003 and parameters: {'max_depth': 14, 'n_estimators': 48, 'learning_rate': 0.7436704297351775, 'colsample_bytree': 0.5822107008573151, 'reg_alpha': 4, 'reg_lambda': 8}. Best is trial 0 with value: 2813.0052598074003.\n",
      "[I 2020-10-08 22:31:28,487] Trial 1 finished with value: 2752.299025235469 and parameters: {'max_depth': 11, 'n_estimators': 212, 'learning_rate': 0.6813047017599905, 'colsample_bytree': 0.45006976901015405, 'reg_alpha': 7, 'reg_lambda': 9}. Best is trial 1 with value: 2752.299025235469.\n",
      "[I 2020-10-08 22:38:28,542] Trial 2 finished with value: 2763.4347519476623 and parameters: {'max_depth': 26, 'n_estimators': 397, 'learning_rate': 0.4450973669431999, 'colsample_bytree': 0.7333800304661316, 'reg_alpha': 8, 'reg_lambda': 9}. Best is trial 1 with value: 2752.299025235469.\n",
      "[I 2020-10-08 22:39:56,989] Trial 3 finished with value: 3232.767874840755 and parameters: {'max_depth': 19, 'n_estimators': 166, 'learning_rate': 0.8524708871836397, 'colsample_bytree': 0.36991692833381473, 'reg_alpha': 5, 'reg_lambda': 4}. Best is trial 1 with value: 2752.299025235469.\n",
      "[I 2020-10-08 22:41:33,595] Trial 4 finished with value: 3289.110391270318 and parameters: {'max_depth': 18, 'n_estimators': 244, 'learning_rate': 0.9614396430577418, 'colsample_bytree': 0.21228062433011613, 'reg_alpha': 1, 'reg_lambda': 3}. Best is trial 1 with value: 2752.299025235469.\n",
      "[I 2020-10-08 22:42:33,665] Trial 5 finished with value: 2502.6046798513585 and parameters: {'max_depth': 5, 'n_estimators': 473, 'learning_rate': 0.8208196767816798, 'colsample_bytree': 0.5163819836409639, 'reg_alpha': 4, 'reg_lambda': 8}. Best is trial 5 with value: 2502.6046798513585.\n",
      "[I 2020-10-08 22:43:04,039] Trial 6 finished with value: 2605.303288298908 and parameters: {'max_depth': 2, 'n_estimators': 450, 'learning_rate': 0.22901795866814179, 'colsample_bytree': 0.8557351336396671, 'reg_alpha': 5, 'reg_lambda': 8}. Best is trial 5 with value: 2502.6046798513585.\n",
      "[I 2020-10-08 22:43:48,194] Trial 7 finished with value: 2487.992284539929 and parameters: {'max_depth': 5, 'n_estimators': 460, 'learning_rate': 0.7632263594160623, 'colsample_bytree': 0.2732402835394975, 'reg_alpha': 1, 'reg_lambda': 1}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:43:55,399] Trial 8 finished with value: 2564.519037997684 and parameters: {'max_depth': 6, 'n_estimators': 54, 'learning_rate': 0.23470738046531486, 'colsample_bytree': 0.27785711060127016, 'reg_alpha': 2, 'reg_lambda': 5}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:44:09,446] Trial 9 finished with value: 2507.676573211151 and parameters: {'max_depth': 11, 'n_estimators': 43, 'learning_rate': 0.42355711051640743, 'colsample_bytree': 0.4496255630394732, 'reg_alpha': 2, 'reg_lambda': 8}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:47:13,815] Trial 10 finished with value: 2873.693115663091 and parameters: {'max_depth': 29, 'n_estimators': 366, 'learning_rate': 0.6142615718178988, 'colsample_bytree': 0.11105493717218964, 'reg_alpha': 10, 'reg_lambda': 1}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:47:44,784] Trial 11 finished with value: 2549.9081349536073 and parameters: {'max_depth': 2, 'n_estimators': 488, 'learning_rate': 0.9945272958758469, 'colsample_bytree': 0.6109332023073577, 'reg_alpha': 3, 'reg_lambda': 1}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:48:23,872] Trial 12 finished with value: 2523.708157726336 and parameters: {'max_depth': 6, 'n_estimators': 339, 'learning_rate': 0.828520797551441, 'colsample_bytree': 0.2941436782104308, 'reg_alpha': 1, 'reg_lambda': 6}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:49:23,282] Trial 13 finished with value: 2518.383630749342 and parameters: {'max_depth': 7, 'n_estimators': 496, 'learning_rate': 0.8897317554790142, 'colsample_bytree': 0.12141079645677, 'reg_alpha': 7, 'reg_lambda': 6}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:49:44,177] Trial 14 finished with value: 2584.417639247531 and parameters: {'max_depth': 2, 'n_estimators': 318, 'learning_rate': 0.53607874269738, 'colsample_bytree': 0.5989893589827158, 'reg_alpha': 3, 'reg_lambda': 10}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:51:39,731] Trial 15 finished with value: 2777.8419743897266 and parameters: {'max_depth': 9, 'n_estimators': 429, 'learning_rate': 0.7510455491757603, 'colsample_bytree': 0.7000433465840544, 'reg_alpha': 4, 'reg_lambda': 2}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:57:19,134] Trial 16 finished with value: 2985.4964865133375 and parameters: {'max_depth': 22, 'n_estimators': 498, 'learning_rate': 0.5864975493339667, 'colsample_bytree': 0.3763663458412993, 'reg_alpha': 1, 'reg_lambda': 7}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 22:57:42,273] Trial 17 finished with value: 2511.428257467091 and parameters: {'max_depth': 4, 'n_estimators': 294, 'learning_rate': 0.7675063599569801, 'colsample_bytree': 0.20142318990424174, 'reg_alpha': 6, 'reg_lambda': 10}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 23:00:37,824] Trial 18 finished with value: 3207.8778262821934 and parameters: {'max_depth': 14, 'n_estimators': 438, 'learning_rate': 0.9235989831934117, 'colsample_bytree': 0.4825839189453503, 'reg_alpha': 10, 'reg_lambda': 4}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 23:01:03,961] Trial 19 finished with value: 2613.486801845216 and parameters: {'max_depth': 10, 'n_estimators': 134, 'learning_rate': 0.6792687218174112, 'colsample_bytree': 0.367434199649576, 'reg_alpha': 3, 'reg_lambda': 7}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 23:03:42,608] Trial 20 finished with value: 2727.178074532208 and parameters: {'max_depth': 14, 'n_estimators': 387, 'learning_rate': 0.47408980347366986, 'colsample_bytree': 0.5194665732312526, 'reg_alpha': 2, 'reg_lambda': 5}. Best is trial 7 with value: 2487.992284539929.\n",
      "[I 2020-10-08 23:04:01,435] Trial 21 finished with value: 2467.838782904367 and parameters: {'max_depth': 8, 'n_estimators': 120, 'learning_rate': 0.3456888692300487, 'colsample_bytree': 0.42217860332657825, 'reg_alpha': 2, 'reg_lambda': 8}. Best is trial 21 with value: 2467.838782904367.\n",
      "[I 2020-10-08 23:04:11,240] Trial 22 finished with value: 2586.722617280327 and parameters: {'max_depth': 4, 'n_estimators': 107, 'learning_rate': 0.3162092114915252, 'colsample_bytree': 0.2917311714877064, 'reg_alpha': 4, 'reg_lambda': 7}. Best is trial 21 with value: 2467.838782904367.\n",
      "[I 2020-10-08 23:04:52,136] Trial 23 finished with value: 2454.8885776133366 and parameters: {'max_depth': 8, 'n_estimators': 266, 'learning_rate': 0.33168910421934505, 'colsample_bytree': 0.4040845325512566, 'reg_alpha': 2, 'reg_lambda': 9}. Best is trial 23 with value: 2454.8885776133366.\n",
      "[I 2020-10-08 23:04:54,032] Trial 24 finished with value: 6355.61283508386 and parameters: {'max_depth': 9, 'n_estimators': 4, 'learning_rate': 0.14389252740662684, 'colsample_bytree': 0.376696873039459, 'reg_alpha': 1, 'reg_lambda': 9}. Best is trial 23 with value: 2454.8885776133366.\n",
      "[I 2020-10-08 23:05:24,192] Trial 25 finished with value: 2458.0250837221274 and parameters: {'max_depth': 8, 'n_estimators': 198, 'learning_rate': 0.3482275540320084, 'colsample_bytree': 0.2229653411202679, 'reg_alpha': 2, 'reg_lambda': 10}. Best is trial 23 with value: 2454.8885776133366.\n",
      "[I 2020-10-08 23:05:55,301] Trial 26 finished with value: 2467.6888000016925 and parameters: {'max_depth': 8, 'n_estimators': 219, 'learning_rate': 0.3466490105872005, 'colsample_bytree': 0.15646042554714895, 'reg_alpha': 2, 'reg_lambda': 10}. Best is trial 23 with value: 2454.8885776133366.\n",
      "[I 2020-10-08 23:06:41,463] Trial 27 finished with value: 2511.5360090207664 and parameters: {'max_depth': 12, 'n_estimators': 212, 'learning_rate': 0.3604963972065957, 'colsample_bytree': 0.17952778927694735, 'reg_alpha': 3, 'reg_lambda': 10}. Best is trial 23 with value: 2454.8885776133366.\n",
      "[I 2020-10-08 23:08:06,489] Trial 28 finished with value: 2463.2146513694956 and parameters: {'max_depth': 16, 'n_estimators': 287, 'learning_rate': 0.11179480915027651, 'colsample_bytree': 0.14202562873920424, 'reg_alpha': 2, 'reg_lambda': 10}. Best is trial 23 with value: 2454.8885776133366.\n",
      "[I 2020-10-08 23:10:02,393] Trial 29 finished with value: 2507.6991817304724 and parameters: {'max_depth': 17, 'n_estimators': 275, 'learning_rate': 0.11658718150024722, 'colsample_bytree': 0.2564454160047017, 'reg_alpha': 3, 'reg_lambda': 9}. Best is trial 23 with value: 2454.8885776133366.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBR RMSE 2442.506719650969\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def create_model(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 1, 500)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.1, 1)\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.1, 0.9)\n",
    "    #num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n",
    "    #min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n",
    "    reg_alpha = trial.suggest_int(\"reg_alpha\", 1, 10)\n",
    "    reg_lambda = trial.suggest_int(\"reg_lambda\", 1, 10)\n",
    "    model = XGBRegressor(\n",
    "        learning_rate=learning_rate, \n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        #num_leaves=num_leaves, \n",
    "        #min_child_samples=min_child_samples,\n",
    "        random_state=1999,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sampler = TPESampler(seed=0)\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_trn, y_trn)\n",
    "    preds = model.predict(X_val)\n",
    "    score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "xgb_params = study.best_params\n",
    "xgb_params['random_state'] = 0\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "xgb.fit(X_trn, y_trn)\n",
    "preds = xgb.predict(X_val)\n",
    "print('Optimized XGBR RMSE', np.sqrt(mean_squared_error(y_val, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score is: 2442.506719650969\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb = xgb\n",
    "xgb.fit(X_trn, y_trn)\n",
    "preds = xgb.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'RMSE score is: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Fold1============================\n",
      "\n",
      " RMSE score for Validation set is : 2432.770566062838\n",
      "\n",
      "=========================Fold2============================\n",
      "\n",
      " RMSE score for Validation set is : 2451.748402985729\n",
      "\n",
      "=========================Fold3============================\n",
      "\n",
      " RMSE score for Validation set is : 2455.147101330811\n",
      "\n",
      "=========================Fold4============================\n",
      "\n",
      " RMSE score for Validation set is : 2450.335227558207\n",
      "\n",
      "=========================Fold5============================\n",
      "\n",
      " RMSE score for Validation set is : 2449.4270833351206\n",
      "\n",
      "\n",
      "RMSE score for oofs is 2447.898107978903\n"
     ]
    }
   ],
   "source": [
    "# Cross val\n",
    "\n",
    "xgb_fe_oofs, xgb_fe_preds = boosting_cross_val(xgb, train_proc, test_proc, features, 'xgb')\n",
    "sample_sub['Purchase'] = xgb_fe_preds\n",
    "sample_sub.to_csv(r\"D:\\Data Science\\Projects\\Analytics vidya\\Black Friday Sales Prediction\\final\\XGB_FE_Boosting.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4094.8099743\ttotal: 165ms\tremaining: 2m 15s\n",
      "1:\tlearn: 3538.6939085\ttotal: 332ms\tremaining: 2m 16s\n",
      "2:\tlearn: 3186.5311065\ttotal: 649ms\tremaining: 2m 57s\n",
      "3:\tlearn: 2996.2617617\ttotal: 852ms\tremaining: 2m 54s\n",
      "4:\tlearn: 2897.4472686\ttotal: 937ms\tremaining: 2m 33s\n",
      "5:\tlearn: 2839.1599806\ttotal: 2.1s\tremaining: 4m 45s\n",
      "6:\tlearn: 2793.1522435\ttotal: 2.18s\tremaining: 4m 13s\n",
      "7:\tlearn: 2769.9820793\ttotal: 3.35s\tremaining: 5m 41s\n",
      "8:\tlearn: 2748.3652508\ttotal: 4.16s\tremaining: 6m 15s\n",
      "9:\tlearn: 2731.8352068\ttotal: 4.64s\tremaining: 6m 16s\n",
      "10:\tlearn: 2716.0784362\ttotal: 5.73s\tremaining: 7m 2s\n",
      "11:\tlearn: 2708.8969950\ttotal: 6.89s\tremaining: 7m 45s\n",
      "12:\tlearn: 2701.3592483\ttotal: 7.76s\tremaining: 8m 2s\n",
      "13:\tlearn: 2692.5575286\ttotal: 9.04s\tremaining: 8m 41s\n",
      "14:\tlearn: 2682.7152670\ttotal: 10.2s\tremaining: 9m 10s\n",
      "15:\tlearn: 2676.8902614\ttotal: 11.5s\tremaining: 9m 38s\n",
      "16:\tlearn: 2672.9233313\ttotal: 12.6s\tremaining: 9m 55s\n",
      "17:\tlearn: 2663.6799835\ttotal: 13.7s\tremaining: 10m 13s\n",
      "18:\tlearn: 2660.4213512\ttotal: 14.9s\tremaining: 10m 28s\n",
      "19:\tlearn: 2656.7209429\ttotal: 16.1s\tremaining: 10m 46s\n",
      "20:\tlearn: 2653.7441074\ttotal: 17.5s\tremaining: 11m 6s\n",
      "21:\tlearn: 2645.4784793\ttotal: 18.6s\tremaining: 11m 15s\n",
      "22:\tlearn: 2642.7789426\ttotal: 19.8s\tremaining: 11m 28s\n",
      "23:\tlearn: 2640.1340637\ttotal: 19.9s\tremaining: 11m 2s\n",
      "24:\tlearn: 2637.1407778\ttotal: 21.2s\tremaining: 11m 16s\n",
      "25:\tlearn: 2627.5583233\ttotal: 22.3s\tremaining: 11m 23s\n",
      "26:\tlearn: 2624.7516730\ttotal: 23.6s\tremaining: 11m 34s\n",
      "27:\tlearn: 2623.8664923\ttotal: 23.6s\tremaining: 11m 9s\n",
      "28:\tlearn: 2620.3967428\ttotal: 24.8s\tremaining: 11m 18s\n",
      "29:\tlearn: 2617.3248560\ttotal: 26s\tremaining: 11m 25s\n",
      "30:\tlearn: 2612.4229786\ttotal: 27.3s\tremaining: 11m 36s\n",
      "31:\tlearn: 2608.8634695\ttotal: 28.6s\tremaining: 11m 45s\n",
      "32:\tlearn: 2605.4232222\ttotal: 29.7s\tremaining: 11m 49s\n",
      "33:\tlearn: 2603.6274539\ttotal: 30.8s\tremaining: 11m 54s\n",
      "34:\tlearn: 2600.3681416\ttotal: 31.9s\tremaining: 11m 57s\n",
      "35:\tlearn: 2597.9146244\ttotal: 33s\tremaining: 12m 1s\n",
      "36:\tlearn: 2595.0787683\ttotal: 34.2s\tremaining: 12m 5s\n",
      "37:\tlearn: 2592.0988038\ttotal: 35.2s\tremaining: 12m 5s\n",
      "38:\tlearn: 2589.7106318\ttotal: 36.4s\tremaining: 12m 10s\n",
      "39:\tlearn: 2588.2902652\ttotal: 37.6s\tremaining: 12m 14s\n",
      "40:\tlearn: 2585.8890898\ttotal: 38.7s\tremaining: 12m 17s\n",
      "41:\tlearn: 2584.2428205\ttotal: 40s\tremaining: 12m 22s\n",
      "42:\tlearn: 2583.5386340\ttotal: 41.1s\tremaining: 12m 24s\n",
      "43:\tlearn: 2580.9409848\ttotal: 42.4s\tremaining: 12m 29s\n",
      "44:\tlearn: 2577.4845156\ttotal: 43.8s\tremaining: 12m 36s\n",
      "45:\tlearn: 2575.4477605\ttotal: 45s\tremaining: 12m 39s\n",
      "46:\tlearn: 2574.2341364\ttotal: 46s\tremaining: 12m 39s\n",
      "47:\tlearn: 2571.4587022\ttotal: 47.2s\tremaining: 12m 41s\n",
      "48:\tlearn: 2569.6612531\ttotal: 48.3s\tremaining: 12m 41s\n",
      "49:\tlearn: 2568.9253174\ttotal: 49.3s\tremaining: 12m 41s\n",
      "50:\tlearn: 2566.8967370\ttotal: 50.6s\tremaining: 12m 45s\n",
      "51:\tlearn: 2566.3875633\ttotal: 51.8s\tremaining: 12m 46s\n",
      "52:\tlearn: 2564.0953564\ttotal: 53s\tremaining: 12m 49s\n",
      "53:\tlearn: 2562.4908601\ttotal: 54.2s\tremaining: 12m 50s\n",
      "54:\tlearn: 2561.7418615\ttotal: 55.4s\tremaining: 12m 52s\n",
      "55:\tlearn: 2561.0172965\ttotal: 56.7s\tremaining: 12m 55s\n",
      "56:\tlearn: 2559.5290115\ttotal: 57.9s\tremaining: 12m 57s\n",
      "57:\tlearn: 2558.3422321\ttotal: 59.1s\tremaining: 12m 58s\n",
      "58:\tlearn: 2557.4253548\ttotal: 1m\tremaining: 12m 58s\n",
      "59:\tlearn: 2556.2787693\ttotal: 1m 1s\tremaining: 12m 56s\n",
      "60:\tlearn: 2554.4245844\ttotal: 1m 2s\tremaining: 12m 56s\n",
      "61:\tlearn: 2553.1421529\ttotal: 1m 3s\tremaining: 12m 57s\n",
      "62:\tlearn: 2551.6025669\ttotal: 1m 4s\tremaining: 12m 55s\n",
      "63:\tlearn: 2549.0704004\ttotal: 1m 5s\tremaining: 12m 56s\n",
      "64:\tlearn: 2547.4487566\ttotal: 1m 6s\tremaining: 12m 56s\n",
      "65:\tlearn: 2545.3979125\ttotal: 1m 7s\tremaining: 12m 57s\n",
      "66:\tlearn: 2543.7517214\ttotal: 1m 8s\tremaining: 12m 54s\n",
      "67:\tlearn: 2543.2630427\ttotal: 1m 9s\tremaining: 12m 54s\n",
      "68:\tlearn: 2542.2074936\ttotal: 1m 11s\tremaining: 12m 54s\n",
      "69:\tlearn: 2540.8785580\ttotal: 1m 12s\tremaining: 12m 56s\n",
      "70:\tlearn: 2540.6992980\ttotal: 1m 12s\tremaining: 12m 44s\n",
      "71:\tlearn: 2539.7710855\ttotal: 1m 13s\tremaining: 12m 46s\n",
      "72:\tlearn: 2537.6788095\ttotal: 1m 14s\tremaining: 12m 46s\n",
      "73:\tlearn: 2536.3915906\ttotal: 1m 15s\tremaining: 12m 46s\n",
      "74:\tlearn: 2535.4219225\ttotal: 1m 17s\tremaining: 12m 47s\n",
      "75:\tlearn: 2534.1181297\ttotal: 1m 18s\tremaining: 12m 48s\n",
      "76:\tlearn: 2533.4955518\ttotal: 1m 19s\tremaining: 12m 49s\n",
      "77:\tlearn: 2532.4594723\ttotal: 1m 20s\tremaining: 12m 50s\n",
      "78:\tlearn: 2531.9381802\ttotal: 1m 21s\tremaining: 12m 50s\n",
      "79:\tlearn: 2531.7362645\ttotal: 1m 23s\tremaining: 12m 49s\n",
      "80:\tlearn: 2529.8678865\ttotal: 1m 24s\tremaining: 12m 49s\n",
      "81:\tlearn: 2529.6014817\ttotal: 1m 25s\tremaining: 12m 48s\n",
      "82:\tlearn: 2528.7611201\ttotal: 1m 26s\tremaining: 12m 47s\n",
      "83:\tlearn: 2528.3940141\ttotal: 1m 26s\tremaining: 12m 38s\n",
      "84:\tlearn: 2527.3579102\ttotal: 1m 27s\tremaining: 12m 38s\n",
      "85:\tlearn: 2524.8332297\ttotal: 1m 28s\tremaining: 12m 41s\n",
      "86:\tlearn: 2524.6570183\ttotal: 1m 30s\tremaining: 12m 41s\n",
      "87:\tlearn: 2523.4265387\ttotal: 1m 31s\tremaining: 12m 41s\n",
      "88:\tlearn: 2522.0364036\ttotal: 1m 32s\tremaining: 12m 41s\n",
      "89:\tlearn: 2521.5908587\ttotal: 1m 33s\tremaining: 12m 39s\n",
      "90:\tlearn: 2520.1764123\ttotal: 1m 34s\tremaining: 12m 37s\n",
      "91:\tlearn: 2519.2137599\ttotal: 1m 35s\tremaining: 12m 37s\n",
      "92:\tlearn: 2518.6013543\ttotal: 1m 36s\tremaining: 12m 37s\n",
      "93:\tlearn: 2517.7278029\ttotal: 1m 37s\tremaining: 12m 35s\n",
      "94:\tlearn: 2517.5685522\ttotal: 1m 38s\tremaining: 12m 35s\n",
      "95:\tlearn: 2516.0809650\ttotal: 1m 39s\tremaining: 12m 36s\n",
      "96:\tlearn: 2514.7327420\ttotal: 1m 41s\tremaining: 12m 36s\n",
      "97:\tlearn: 2513.3559741\ttotal: 1m 42s\tremaining: 12m 36s\n",
      "98:\tlearn: 2513.0165781\ttotal: 1m 43s\tremaining: 12m 37s\n",
      "99:\tlearn: 2511.8506059\ttotal: 1m 45s\tremaining: 12m 38s\n",
      "100:\tlearn: 2510.7909579\ttotal: 1m 46s\tremaining: 12m 39s\n",
      "101:\tlearn: 2509.4531135\ttotal: 1m 47s\tremaining: 12m 39s\n",
      "102:\tlearn: 2509.0828727\ttotal: 1m 48s\tremaining: 12m 38s\n",
      "103:\tlearn: 2507.8488255\ttotal: 1m 49s\tremaining: 12m 39s\n",
      "104:\tlearn: 2507.5726307\ttotal: 1m 51s\tremaining: 12m 38s\n",
      "105:\tlearn: 2505.8279118\ttotal: 1m 52s\tremaining: 12m 38s\n",
      "106:\tlearn: 2504.8604974\ttotal: 1m 53s\tremaining: 12m 38s\n",
      "107:\tlearn: 2502.0020925\ttotal: 1m 54s\tremaining: 12m 38s\n",
      "108:\tlearn: 2501.7293226\ttotal: 1m 55s\tremaining: 12m 38s\n",
      "109:\tlearn: 2500.2265174\ttotal: 1m 57s\tremaining: 12m 38s\n",
      "110:\tlearn: 2499.0801463\ttotal: 1m 58s\tremaining: 12m 35s\n",
      "111:\tlearn: 2497.9417886\ttotal: 1m 59s\tremaining: 12m 36s\n",
      "112:\tlearn: 2495.7000358\ttotal: 2m\tremaining: 12m 36s\n",
      "113:\tlearn: 2495.3277793\ttotal: 2m 1s\tremaining: 12m 36s\n",
      "114:\tlearn: 2494.4358295\ttotal: 2m 3s\tremaining: 12m 36s\n",
      "115:\tlearn: 2492.4945639\ttotal: 2m 4s\tremaining: 12m 35s\n",
      "116:\tlearn: 2491.9868043\ttotal: 2m 5s\tremaining: 12m 34s\n",
      "117:\tlearn: 2490.4126087\ttotal: 2m 6s\tremaining: 12m 34s\n",
      "118:\tlearn: 2489.1829622\ttotal: 2m 7s\tremaining: 12m 32s\n",
      "119:\tlearn: 2488.3097868\ttotal: 2m 8s\tremaining: 12m 33s\n",
      "120:\tlearn: 2487.4101854\ttotal: 2m 10s\tremaining: 12m 33s\n",
      "121:\tlearn: 2487.2514879\ttotal: 2m 11s\tremaining: 12m 33s\n",
      "122:\tlearn: 2486.2833528\ttotal: 2m 12s\tremaining: 12m 34s\n",
      "123:\tlearn: 2485.4462164\ttotal: 2m 13s\tremaining: 12m 32s\n",
      "124:\tlearn: 2484.2841239\ttotal: 2m 14s\tremaining: 12m 31s\n",
      "125:\tlearn: 2482.4246941\ttotal: 2m 15s\tremaining: 12m 31s\n",
      "126:\tlearn: 2481.4425569\ttotal: 2m 16s\tremaining: 12m 29s\n",
      "127:\tlearn: 2480.4815990\ttotal: 2m 18s\tremaining: 12m 28s\n",
      "128:\tlearn: 2479.0278601\ttotal: 2m 19s\tremaining: 12m 27s\n",
      "129:\tlearn: 2478.0983600\ttotal: 2m 20s\tremaining: 12m 26s\n",
      "130:\tlearn: 2476.9868795\ttotal: 2m 21s\tremaining: 12m 26s\n",
      "131:\tlearn: 2476.0671958\ttotal: 2m 23s\tremaining: 12m 27s\n",
      "132:\tlearn: 2475.0904720\ttotal: 2m 24s\tremaining: 12m 27s\n",
      "133:\tlearn: 2474.0382944\ttotal: 2m 25s\tremaining: 12m 27s\n",
      "134:\tlearn: 2472.6584182\ttotal: 2m 26s\tremaining: 12m 27s\n",
      "135:\tlearn: 2472.5871076\ttotal: 2m 28s\tremaining: 12m 26s\n",
      "136:\tlearn: 2471.5000645\ttotal: 2m 29s\tremaining: 12m 26s\n",
      "137:\tlearn: 2471.1715251\ttotal: 2m 30s\tremaining: 12m 27s\n",
      "138:\tlearn: 2470.2013660\ttotal: 2m 31s\tremaining: 12m 26s\n",
      "139:\tlearn: 2469.2234131\ttotal: 2m 33s\tremaining: 12m 26s\n",
      "140:\tlearn: 2467.1001128\ttotal: 2m 34s\tremaining: 12m 26s\n",
      "141:\tlearn: 2465.5368529\ttotal: 2m 35s\tremaining: 12m 26s\n",
      "142:\tlearn: 2464.5670836\ttotal: 2m 37s\tremaining: 12m 26s\n",
      "143:\tlearn: 2463.1784453\ttotal: 2m 38s\tremaining: 12m 25s\n",
      "144:\tlearn: 2462.6692709\ttotal: 2m 39s\tremaining: 12m 26s\n",
      "145:\tlearn: 2461.2169780\ttotal: 2m 41s\tremaining: 12m 25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146:\tlearn: 2459.4812591\ttotal: 2m 42s\tremaining: 12m 24s\n",
      "147:\tlearn: 2457.3814826\ttotal: 2m 43s\tremaining: 12m 23s\n",
      "148:\tlearn: 2456.1697237\ttotal: 2m 44s\tremaining: 12m 23s\n",
      "149:\tlearn: 2455.1662308\ttotal: 2m 45s\tremaining: 12m 21s\n",
      "150:\tlearn: 2453.9262396\ttotal: 2m 46s\tremaining: 12m 21s\n",
      "151:\tlearn: 2453.8122699\ttotal: 2m 47s\tremaining: 12m 19s\n",
      "152:\tlearn: 2452.3663679\ttotal: 2m 48s\tremaining: 12m 18s\n",
      "153:\tlearn: 2451.4374482\ttotal: 2m 49s\tremaining: 12m 16s\n",
      "154:\tlearn: 2450.4200161\ttotal: 2m 51s\tremaining: 12m 16s\n",
      "155:\tlearn: 2450.1955948\ttotal: 2m 52s\tremaining: 12m 15s\n",
      "156:\tlearn: 2448.9537586\ttotal: 2m 53s\tremaining: 12m 15s\n",
      "157:\tlearn: 2448.3199587\ttotal: 2m 54s\tremaining: 12m 14s\n",
      "158:\tlearn: 2447.2556464\ttotal: 2m 55s\tremaining: 12m 13s\n",
      "159:\tlearn: 2446.6990896\ttotal: 2m 57s\tremaining: 12m 12s\n",
      "160:\tlearn: 2445.8045191\ttotal: 2m 58s\tremaining: 12m 11s\n",
      "161:\tlearn: 2445.0789708\ttotal: 2m 59s\tremaining: 12m 10s\n",
      "162:\tlearn: 2444.3470619\ttotal: 3m\tremaining: 12m 10s\n",
      "163:\tlearn: 2443.2864675\ttotal: 3m 1s\tremaining: 12m 9s\n",
      "164:\tlearn: 2442.3672186\ttotal: 3m 2s\tremaining: 12m 8s\n",
      "165:\tlearn: 2441.3257528\ttotal: 3m 4s\tremaining: 12m 7s\n",
      "166:\tlearn: 2440.8123994\ttotal: 3m 5s\tremaining: 12m 7s\n",
      "167:\tlearn: 2439.6694126\ttotal: 3m 6s\tremaining: 12m 5s\n",
      "168:\tlearn: 2438.7552751\ttotal: 3m 7s\tremaining: 12m 5s\n",
      "169:\tlearn: 2437.8415764\ttotal: 3m 8s\tremaining: 12m 4s\n",
      "170:\tlearn: 2437.7624138\ttotal: 3m 10s\tremaining: 12m 4s\n",
      "171:\tlearn: 2437.1658026\ttotal: 3m 11s\tremaining: 12m 3s\n",
      "172:\tlearn: 2436.2764552\ttotal: 3m 12s\tremaining: 12m 3s\n",
      "173:\tlearn: 2435.7541571\ttotal: 3m 13s\tremaining: 12m 2s\n",
      "174:\tlearn: 2434.9839957\ttotal: 3m 15s\tremaining: 12m 1s\n",
      "175:\tlearn: 2434.2652715\ttotal: 3m 16s\tremaining: 12m\n",
      "176:\tlearn: 2433.3216381\ttotal: 3m 17s\tremaining: 11m 59s\n",
      "177:\tlearn: 2432.6877591\ttotal: 3m 18s\tremaining: 11m 59s\n",
      "178:\tlearn: 2431.8660642\ttotal: 3m 19s\tremaining: 11m 57s\n",
      "179:\tlearn: 2430.9592023\ttotal: 3m 20s\tremaining: 11m 56s\n",
      "180:\tlearn: 2430.0095594\ttotal: 3m 22s\tremaining: 11m 56s\n",
      "181:\tlearn: 2429.2883772\ttotal: 3m 23s\tremaining: 11m 55s\n",
      "182:\tlearn: 2427.6553170\ttotal: 3m 24s\tremaining: 11m 54s\n",
      "183:\tlearn: 2427.4674014\ttotal: 3m 25s\tremaining: 11m 52s\n",
      "184:\tlearn: 2426.7459692\ttotal: 3m 26s\tremaining: 11m 52s\n",
      "185:\tlearn: 2426.2081053\ttotal: 3m 28s\tremaining: 11m 51s\n",
      "186:\tlearn: 2425.4759512\ttotal: 3m 29s\tremaining: 11m 51s\n",
      "187:\tlearn: 2424.5891975\ttotal: 3m 30s\tremaining: 11m 49s\n",
      "188:\tlearn: 2423.7689610\ttotal: 3m 31s\tremaining: 11m 49s\n",
      "189:\tlearn: 2423.0005003\ttotal: 3m 33s\tremaining: 11m 48s\n",
      "190:\tlearn: 2422.3043289\ttotal: 3m 34s\tremaining: 11m 47s\n",
      "191:\tlearn: 2421.4851389\ttotal: 3m 35s\tremaining: 11m 46s\n",
      "192:\tlearn: 2420.4488750\ttotal: 3m 36s\tremaining: 11m 45s\n",
      "193:\tlearn: 2420.0275744\ttotal: 3m 37s\tremaining: 11m 43s\n",
      "194:\tlearn: 2419.5620650\ttotal: 3m 38s\tremaining: 11m 43s\n",
      "195:\tlearn: 2419.1148328\ttotal: 3m 39s\tremaining: 11m 42s\n",
      "196:\tlearn: 2418.4756104\ttotal: 3m 41s\tremaining: 11m 41s\n",
      "197:\tlearn: 2417.7828790\ttotal: 3m 41s\tremaining: 11m 39s\n",
      "198:\tlearn: 2417.1384510\ttotal: 3m 43s\tremaining: 11m 38s\n",
      "199:\tlearn: 2416.7537124\ttotal: 3m 44s\tremaining: 11m 37s\n",
      "200:\tlearn: 2415.9953033\ttotal: 3m 45s\tremaining: 11m 36s\n",
      "201:\tlearn: 2415.5435531\ttotal: 3m 46s\tremaining: 11m 35s\n",
      "202:\tlearn: 2414.8607620\ttotal: 3m 47s\tremaining: 11m 34s\n",
      "203:\tlearn: 2414.0015564\ttotal: 3m 48s\tremaining: 11m 33s\n",
      "204:\tlearn: 2413.2082246\ttotal: 3m 50s\tremaining: 11m 32s\n",
      "205:\tlearn: 2412.4936506\ttotal: 3m 51s\tremaining: 11m 32s\n",
      "206:\tlearn: 2411.2846592\ttotal: 3m 52s\tremaining: 11m 31s\n",
      "207:\tlearn: 2410.4025766\ttotal: 3m 53s\tremaining: 11m 30s\n",
      "208:\tlearn: 2409.8313714\ttotal: 3m 55s\tremaining: 11m 29s\n",
      "209:\tlearn: 2409.1427364\ttotal: 3m 56s\tremaining: 11m 28s\n",
      "210:\tlearn: 2408.3697618\ttotal: 3m 57s\tremaining: 11m 26s\n",
      "211:\tlearn: 2408.1378453\ttotal: 3m 58s\tremaining: 11m 25s\n",
      "212:\tlearn: 2407.3285163\ttotal: 3m 59s\tremaining: 11m 25s\n",
      "213:\tlearn: 2406.9718057\ttotal: 4m\tremaining: 11m 24s\n",
      "214:\tlearn: 2406.4318811\ttotal: 4m 2s\tremaining: 11m 23s\n",
      "215:\tlearn: 2406.3579361\ttotal: 4m 3s\tremaining: 11m 22s\n",
      "216:\tlearn: 2406.2759317\ttotal: 4m 4s\tremaining: 11m 21s\n",
      "217:\tlearn: 2405.9260449\ttotal: 4m 5s\tremaining: 11m 20s\n",
      "218:\tlearn: 2405.0742756\ttotal: 4m 7s\tremaining: 11m 20s\n",
      "219:\tlearn: 2404.2419704\ttotal: 4m 8s\tremaining: 11m 19s\n",
      "220:\tlearn: 2403.6342159\ttotal: 4m 9s\tremaining: 11m 19s\n",
      "221:\tlearn: 2402.9442545\ttotal: 4m 11s\tremaining: 11m 18s\n",
      "222:\tlearn: 2402.8479467\ttotal: 4m 12s\tremaining: 11m 17s\n",
      "223:\tlearn: 2402.0649557\ttotal: 4m 13s\tremaining: 11m 16s\n",
      "224:\tlearn: 2402.0184351\ttotal: 4m 14s\tremaining: 11m 15s\n",
      "225:\tlearn: 2401.7994846\ttotal: 4m 15s\tremaining: 11m 14s\n",
      "226:\tlearn: 2401.4138648\ttotal: 4m 17s\tremaining: 11m 13s\n",
      "227:\tlearn: 2400.4959911\ttotal: 4m 18s\tremaining: 11m 13s\n",
      "228:\tlearn: 2400.1784575\ttotal: 4m 19s\tremaining: 11m 12s\n",
      "229:\tlearn: 2399.2157302\ttotal: 4m 21s\tremaining: 11m 12s\n",
      "230:\tlearn: 2398.4497778\ttotal: 4m 22s\tremaining: 11m 11s\n",
      "231:\tlearn: 2397.8621131\ttotal: 4m 23s\tremaining: 11m 9s\n",
      "232:\tlearn: 2397.1056560\ttotal: 4m 24s\tremaining: 11m 8s\n",
      "233:\tlearn: 2396.4308754\ttotal: 4m 25s\tremaining: 11m 7s\n",
      "234:\tlearn: 2395.6268251\ttotal: 4m 27s\tremaining: 11m 7s\n",
      "235:\tlearn: 2395.5395028\ttotal: 4m 28s\tremaining: 11m 5s\n",
      "236:\tlearn: 2395.0116175\ttotal: 4m 29s\tremaining: 11m 4s\n",
      "237:\tlearn: 2394.2987991\ttotal: 4m 30s\tremaining: 11m 3s\n",
      "238:\tlearn: 2393.6101584\ttotal: 4m 31s\tremaining: 11m 2s\n",
      "239:\tlearn: 2392.8894635\ttotal: 4m 32s\tremaining: 11m 1s\n",
      "240:\tlearn: 2392.0800146\ttotal: 4m 34s\tremaining: 11m\n",
      "241:\tlearn: 2391.4319237\ttotal: 4m 35s\tremaining: 10m 59s\n",
      "242:\tlearn: 2390.8428865\ttotal: 4m 36s\tremaining: 10m 58s\n",
      "243:\tlearn: 2390.2860754\ttotal: 4m 37s\tremaining: 10m 57s\n",
      "244:\tlearn: 2389.7233176\ttotal: 4m 38s\tremaining: 10m 56s\n",
      "245:\tlearn: 2388.8929270\ttotal: 4m 40s\tremaining: 10m 55s\n",
      "246:\tlearn: 2388.8300453\ttotal: 4m 41s\tremaining: 10m 54s\n",
      "247:\tlearn: 2387.7390830\ttotal: 4m 42s\tremaining: 10m 54s\n",
      "248:\tlearn: 2387.1336217\ttotal: 4m 43s\tremaining: 10m 53s\n",
      "249:\tlearn: 2386.5958024\ttotal: 4m 45s\tremaining: 10m 52s\n",
      "250:\tlearn: 2386.1268378\ttotal: 4m 46s\tremaining: 10m 51s\n",
      "251:\tlearn: 2385.4490090\ttotal: 4m 47s\tremaining: 10m 50s\n",
      "252:\tlearn: 2384.7627830\ttotal: 4m 48s\tremaining: 10m 49s\n",
      "253:\tlearn: 2384.3965943\ttotal: 4m 49s\tremaining: 10m 48s\n",
      "254:\tlearn: 2383.6944253\ttotal: 4m 51s\tremaining: 10m 47s\n",
      "255:\tlearn: 2383.6873271\ttotal: 4m 51s\tremaining: 10m 43s\n",
      "256:\tlearn: 2383.3093300\ttotal: 4m 52s\tremaining: 10m 43s\n",
      "257:\tlearn: 2382.6875226\ttotal: 4m 53s\tremaining: 10m 42s\n",
      "258:\tlearn: 2382.0989972\ttotal: 4m 54s\tremaining: 10m 40s\n",
      "259:\tlearn: 2381.7432036\ttotal: 4m 55s\tremaining: 10m 39s\n",
      "260:\tlearn: 2381.0414114\ttotal: 4m 57s\tremaining: 10m 38s\n",
      "261:\tlearn: 2380.2548949\ttotal: 4m 58s\tremaining: 10m 37s\n",
      "262:\tlearn: 2379.5543351\ttotal: 4m 59s\tremaining: 10m 36s\n",
      "263:\tlearn: 2379.3096583\ttotal: 5m\tremaining: 10m 35s\n",
      "264:\tlearn: 2378.4855497\ttotal: 5m 1s\tremaining: 10m 34s\n",
      "265:\tlearn: 2377.8676546\ttotal: 5m 3s\tremaining: 10m 33s\n",
      "266:\tlearn: 2377.2164008\ttotal: 5m 4s\tremaining: 10m 32s\n",
      "267:\tlearn: 2376.7445923\ttotal: 5m 5s\tremaining: 10m 31s\n",
      "268:\tlearn: 2376.2053394\ttotal: 5m 6s\tremaining: 10m 30s\n",
      "269:\tlearn: 2375.4050176\ttotal: 5m 8s\tremaining: 10m 30s\n",
      "270:\tlearn: 2374.4553836\ttotal: 5m 9s\tremaining: 10m 29s\n",
      "271:\tlearn: 2373.7204020\ttotal: 5m 11s\tremaining: 10m 28s\n",
      "272:\tlearn: 2373.4209649\ttotal: 5m 12s\tremaining: 10m 27s\n",
      "273:\tlearn: 2372.7839242\ttotal: 5m 13s\tremaining: 10m 27s\n",
      "274:\tlearn: 2371.9980221\ttotal: 5m 14s\tremaining: 10m 26s\n",
      "275:\tlearn: 2371.7624151\ttotal: 5m 15s\tremaining: 10m 25s\n",
      "276:\tlearn: 2370.9985780\ttotal: 5m 17s\tremaining: 10m 24s\n",
      "277:\tlearn: 2370.3569293\ttotal: 5m 18s\tremaining: 10m 22s\n",
      "278:\tlearn: 2369.6012029\ttotal: 5m 19s\tremaining: 10m 21s\n",
      "279:\tlearn: 2369.0607627\ttotal: 5m 20s\tremaining: 10m 20s\n",
      "280:\tlearn: 2368.4897354\ttotal: 5m 21s\tremaining: 10m 19s\n",
      "281:\tlearn: 2367.8535494\ttotal: 5m 22s\tremaining: 10m 18s\n",
      "282:\tlearn: 2367.2040418\ttotal: 5m 24s\tremaining: 10m 17s\n",
      "283:\tlearn: 2366.4443172\ttotal: 5m 25s\tremaining: 10m 16s\n",
      "284:\tlearn: 2365.7184311\ttotal: 5m 26s\tremaining: 10m 14s\n",
      "285:\tlearn: 2365.1836864\ttotal: 5m 27s\tremaining: 10m 13s\n",
      "286:\tlearn: 2364.5723697\ttotal: 5m 28s\tremaining: 10m 12s\n",
      "287:\tlearn: 2363.9921588\ttotal: 5m 29s\tremaining: 10m 11s\n",
      "288:\tlearn: 2363.4723924\ttotal: 5m 31s\tremaining: 10m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289:\tlearn: 2362.6384938\ttotal: 5m 32s\tremaining: 10m 9s\n",
      "290:\tlearn: 2362.5706611\ttotal: 5m 33s\tremaining: 10m 8s\n",
      "291:\tlearn: 2362.0175621\ttotal: 5m 34s\tremaining: 10m 7s\n",
      "292:\tlearn: 2361.4900960\ttotal: 5m 35s\tremaining: 10m 6s\n",
      "293:\tlearn: 2360.7399913\ttotal: 5m 37s\tremaining: 10m 5s\n",
      "294:\tlearn: 2360.2881104\ttotal: 5m 38s\tremaining: 10m 4s\n",
      "295:\tlearn: 2359.6027217\ttotal: 5m 39s\tremaining: 10m 3s\n",
      "296:\tlearn: 2358.8197020\ttotal: 5m 40s\tremaining: 10m 2s\n",
      "297:\tlearn: 2358.2494491\ttotal: 5m 42s\tremaining: 10m 1s\n",
      "298:\tlearn: 2357.8534298\ttotal: 5m 43s\tremaining: 10m\n",
      "299:\tlearn: 2357.4472170\ttotal: 5m 44s\tremaining: 9m 59s\n",
      "300:\tlearn: 2357.0391808\ttotal: 5m 45s\tremaining: 9m 58s\n",
      "301:\tlearn: 2356.5192976\ttotal: 5m 47s\tremaining: 9m 57s\n",
      "302:\tlearn: 2356.1984044\ttotal: 5m 48s\tremaining: 9m 56s\n",
      "303:\tlearn: 2355.4630692\ttotal: 5m 49s\tremaining: 9m 55s\n",
      "304:\tlearn: 2355.0162387\ttotal: 5m 50s\tremaining: 9m 54s\n",
      "305:\tlearn: 2354.4020731\ttotal: 5m 52s\tremaining: 9m 53s\n",
      "306:\tlearn: 2353.8845649\ttotal: 5m 53s\tremaining: 9m 52s\n",
      "307:\tlearn: 2353.2315883\ttotal: 5m 54s\tremaining: 9m 51s\n",
      "308:\tlearn: 2352.9196543\ttotal: 5m 55s\tremaining: 9m 50s\n",
      "309:\tlearn: 2352.2545648\ttotal: 5m 56s\tremaining: 9m 49s\n",
      "310:\tlearn: 2351.6961372\ttotal: 5m 57s\tremaining: 9m 47s\n",
      "311:\tlearn: 2350.9809533\ttotal: 5m 58s\tremaining: 9m 46s\n",
      "312:\tlearn: 2350.8975078\ttotal: 5m 59s\tremaining: 9m 45s\n",
      "313:\tlearn: 2350.3973560\ttotal: 6m\tremaining: 9m 43s\n",
      "314:\tlearn: 2349.6139283\ttotal: 6m 2s\tremaining: 9m 42s\n",
      "315:\tlearn: 2348.9900258\ttotal: 6m 3s\tremaining: 9m 41s\n",
      "316:\tlearn: 2348.1997847\ttotal: 6m 4s\tremaining: 9m 40s\n",
      "317:\tlearn: 2347.5707142\ttotal: 6m 5s\tremaining: 9m 39s\n",
      "318:\tlearn: 2346.8845086\ttotal: 6m 6s\tremaining: 9m 38s\n",
      "319:\tlearn: 2346.1369651\ttotal: 6m 8s\tremaining: 9m 37s\n",
      "320:\tlearn: 2345.5114158\ttotal: 6m 9s\tremaining: 9m 36s\n",
      "321:\tlearn: 2344.7394746\ttotal: 6m 10s\tremaining: 9m 35s\n",
      "322:\tlearn: 2344.0626133\ttotal: 6m 11s\tremaining: 9m 34s\n",
      "323:\tlearn: 2344.0065935\ttotal: 6m 13s\tremaining: 9m 33s\n",
      "324:\tlearn: 2343.2933437\ttotal: 6m 14s\tremaining: 9m 32s\n",
      "325:\tlearn: 2342.6463251\ttotal: 6m 15s\tremaining: 9m 30s\n",
      "326:\tlearn: 2342.5840733\ttotal: 6m 16s\tremaining: 9m 29s\n",
      "327:\tlearn: 2342.0834660\ttotal: 6m 17s\tremaining: 9m 28s\n",
      "328:\tlearn: 2341.7747959\ttotal: 6m 18s\tremaining: 9m 27s\n",
      "329:\tlearn: 2341.5044569\ttotal: 6m 19s\tremaining: 9m 26s\n",
      "330:\tlearn: 2340.8239731\ttotal: 6m 21s\tremaining: 9m 25s\n",
      "331:\tlearn: 2340.1624649\ttotal: 6m 22s\tremaining: 9m 24s\n",
      "332:\tlearn: 2339.7158780\ttotal: 6m 23s\tremaining: 9m 23s\n",
      "333:\tlearn: 2339.1636799\ttotal: 6m 24s\tremaining: 9m 22s\n",
      "334:\tlearn: 2338.9088933\ttotal: 6m 26s\tremaining: 9m 21s\n",
      "335:\tlearn: 2338.8081523\ttotal: 6m 27s\tremaining: 9m 20s\n",
      "336:\tlearn: 2338.2717884\ttotal: 6m 28s\tremaining: 9m 19s\n",
      "337:\tlearn: 2337.7308281\ttotal: 6m 29s\tremaining: 9m 18s\n",
      "338:\tlearn: 2337.2725456\ttotal: 6m 31s\tremaining: 9m 17s\n",
      "339:\tlearn: 2337.0953735\ttotal: 6m 32s\tremaining: 9m 16s\n",
      "340:\tlearn: 2336.4131599\ttotal: 6m 33s\tremaining: 9m 15s\n",
      "341:\tlearn: 2335.8349676\ttotal: 6m 34s\tremaining: 9m 13s\n",
      "342:\tlearn: 2335.5824375\ttotal: 6m 34s\tremaining: 9m 11s\n",
      "343:\tlearn: 2335.2987388\ttotal: 6m 35s\tremaining: 9m 10s\n",
      "344:\tlearn: 2335.1568382\ttotal: 6m 37s\tremaining: 9m 9s\n",
      "345:\tlearn: 2334.6966321\ttotal: 6m 38s\tremaining: 9m 8s\n",
      "346:\tlearn: 2334.0337580\ttotal: 6m 39s\tremaining: 9m 7s\n",
      "347:\tlearn: 2333.7343252\ttotal: 6m 40s\tremaining: 9m 6s\n",
      "348:\tlearn: 2333.5765222\ttotal: 6m 42s\tremaining: 9m 4s\n",
      "349:\tlearn: 2333.2589844\ttotal: 6m 43s\tremaining: 9m 3s\n",
      "350:\tlearn: 2332.7785800\ttotal: 6m 44s\tremaining: 9m 2s\n",
      "351:\tlearn: 2332.4775349\ttotal: 6m 45s\tremaining: 9m 1s\n",
      "352:\tlearn: 2331.8552471\ttotal: 6m 46s\tremaining: 9m\n",
      "353:\tlearn: 2331.6699572\ttotal: 6m 47s\tremaining: 8m 59s\n",
      "354:\tlearn: 2331.5240421\ttotal: 6m 49s\tremaining: 8m 58s\n",
      "355:\tlearn: 2331.1408320\ttotal: 6m 50s\tremaining: 8m 57s\n",
      "356:\tlearn: 2330.7500513\ttotal: 6m 51s\tremaining: 8m 55s\n",
      "357:\tlearn: 2330.1480052\ttotal: 6m 52s\tremaining: 8m 54s\n",
      "358:\tlearn: 2329.9243221\ttotal: 6m 53s\tremaining: 8m 53s\n",
      "359:\tlearn: 2329.6068367\ttotal: 6m 54s\tremaining: 8m 52s\n",
      "360:\tlearn: 2329.2210682\ttotal: 6m 56s\tremaining: 8m 51s\n",
      "361:\tlearn: 2328.6718430\ttotal: 6m 57s\tremaining: 8m 50s\n",
      "362:\tlearn: 2327.9776107\ttotal: 6m 58s\tremaining: 8m 49s\n",
      "363:\tlearn: 2327.5047885\ttotal: 7m\tremaining: 8m 48s\n",
      "364:\tlearn: 2327.1960989\ttotal: 7m 1s\tremaining: 8m 47s\n",
      "365:\tlearn: 2326.8610784\ttotal: 7m 2s\tremaining: 8m 46s\n",
      "366:\tlearn: 2326.2526562\ttotal: 7m 3s\tremaining: 8m 45s\n",
      "367:\tlearn: 2326.0748126\ttotal: 7m 4s\tremaining: 8m 44s\n",
      "368:\tlearn: 2325.5975476\ttotal: 7m 5s\tremaining: 8m 42s\n",
      "369:\tlearn: 2325.1814794\ttotal: 7m 7s\tremaining: 8m 41s\n",
      "370:\tlearn: 2324.5743483\ttotal: 7m 8s\tremaining: 8m 40s\n",
      "371:\tlearn: 2324.3708604\ttotal: 7m 9s\tremaining: 8m 39s\n",
      "372:\tlearn: 2323.8593751\ttotal: 7m 10s\tremaining: 8m 38s\n",
      "373:\tlearn: 2323.2477428\ttotal: 7m 12s\tremaining: 8m 37s\n",
      "374:\tlearn: 2322.7114428\ttotal: 7m 13s\tremaining: 8m 36s\n",
      "375:\tlearn: 2322.6064136\ttotal: 7m 14s\tremaining: 8m 35s\n",
      "376:\tlearn: 2322.2514652\ttotal: 7m 15s\tremaining: 8m 34s\n",
      "377:\tlearn: 2321.5290620\ttotal: 7m 17s\tremaining: 8m 33s\n",
      "378:\tlearn: 2320.9515384\ttotal: 7m 18s\tremaining: 8m 32s\n",
      "379:\tlearn: 2320.4364399\ttotal: 7m 19s\tremaining: 8m 31s\n",
      "380:\tlearn: 2320.2074020\ttotal: 7m 20s\tremaining: 8m 29s\n",
      "381:\tlearn: 2319.5916252\ttotal: 7m 21s\tremaining: 8m 28s\n",
      "382:\tlearn: 2319.4355319\ttotal: 7m 22s\tremaining: 8m 27s\n",
      "383:\tlearn: 2319.0524729\ttotal: 7m 23s\tremaining: 8m 25s\n",
      "384:\tlearn: 2318.3781036\ttotal: 7m 24s\tremaining: 8m 24s\n",
      "385:\tlearn: 2317.8578105\ttotal: 7m 25s\tremaining: 8m 23s\n",
      "386:\tlearn: 2317.3537685\ttotal: 7m 26s\tremaining: 8m 22s\n",
      "387:\tlearn: 2316.9123455\ttotal: 7m 28s\tremaining: 8m 21s\n",
      "388:\tlearn: 2316.5508071\ttotal: 7m 29s\tremaining: 8m 20s\n",
      "389:\tlearn: 2315.8193548\ttotal: 7m 30s\tremaining: 8m 19s\n",
      "390:\tlearn: 2315.3003826\ttotal: 7m 31s\tremaining: 8m 17s\n",
      "391:\tlearn: 2314.8436196\ttotal: 7m 32s\tremaining: 8m 16s\n",
      "392:\tlearn: 2314.5503931\ttotal: 7m 33s\tremaining: 8m 15s\n",
      "393:\tlearn: 2314.0694431\ttotal: 7m 35s\tremaining: 8m 14s\n",
      "394:\tlearn: 2313.4108999\ttotal: 7m 36s\tremaining: 8m 13s\n",
      "395:\tlearn: 2312.7539990\ttotal: 7m 37s\tremaining: 8m 12s\n",
      "396:\tlearn: 2312.3054751\ttotal: 7m 38s\tremaining: 8m 11s\n",
      "397:\tlearn: 2312.0107007\ttotal: 7m 40s\tremaining: 8m 10s\n",
      "398:\tlearn: 2311.5305125\ttotal: 7m 41s\tremaining: 8m 9s\n",
      "399:\tlearn: 2311.0940320\ttotal: 7m 42s\tremaining: 8m 7s\n",
      "400:\tlearn: 2310.7292413\ttotal: 7m 43s\tremaining: 8m 6s\n",
      "401:\tlearn: 2310.3454942\ttotal: 7m 44s\tremaining: 8m 5s\n",
      "402:\tlearn: 2309.8046542\ttotal: 7m 46s\tremaining: 8m 4s\n",
      "403:\tlearn: 2309.2798615\ttotal: 7m 47s\tremaining: 8m 3s\n",
      "404:\tlearn: 2308.6932539\ttotal: 7m 48s\tremaining: 8m 2s\n",
      "405:\tlearn: 2308.0666149\ttotal: 7m 49s\tremaining: 8m 1s\n",
      "406:\tlearn: 2307.5796368\ttotal: 7m 50s\tremaining: 7m 59s\n",
      "407:\tlearn: 2307.1522360\ttotal: 7m 51s\tremaining: 7m 58s\n",
      "408:\tlearn: 2306.5292291\ttotal: 7m 53s\tremaining: 7m 57s\n",
      "409:\tlearn: 2305.8683190\ttotal: 7m 54s\tremaining: 7m 56s\n",
      "410:\tlearn: 2305.5405238\ttotal: 7m 55s\tremaining: 7m 55s\n",
      "411:\tlearn: 2305.1055875\ttotal: 7m 57s\tremaining: 7m 54s\n",
      "412:\tlearn: 2304.7160548\ttotal: 7m 58s\tremaining: 7m 53s\n",
      "413:\tlearn: 2304.0686551\ttotal: 7m 59s\tremaining: 7m 52s\n",
      "414:\tlearn: 2303.6014610\ttotal: 8m\tremaining: 7m 51s\n",
      "415:\tlearn: 2303.3834482\ttotal: 8m 1s\tremaining: 7m 50s\n",
      "416:\tlearn: 2303.0053550\ttotal: 8m 3s\tremaining: 7m 49s\n",
      "417:\tlearn: 2302.5714278\ttotal: 8m 4s\tremaining: 7m 48s\n",
      "418:\tlearn: 2302.0384322\ttotal: 8m 5s\tremaining: 7m 46s\n",
      "419:\tlearn: 2301.3832325\ttotal: 8m 6s\tremaining: 7m 45s\n",
      "420:\tlearn: 2300.7949168\ttotal: 8m 7s\tremaining: 7m 44s\n",
      "421:\tlearn: 2300.2314506\ttotal: 8m 8s\tremaining: 7m 43s\n",
      "422:\tlearn: 2299.7823953\ttotal: 8m 10s\tremaining: 7m 42s\n",
      "423:\tlearn: 2299.2483322\ttotal: 8m 11s\tremaining: 7m 41s\n",
      "424:\tlearn: 2298.9837926\ttotal: 8m 12s\tremaining: 7m 40s\n",
      "425:\tlearn: 2298.5778414\ttotal: 8m 13s\tremaining: 7m 39s\n",
      "426:\tlearn: 2298.4305358\ttotal: 8m 14s\tremaining: 7m 37s\n",
      "427:\tlearn: 2298.2343402\ttotal: 8m 15s\tremaining: 7m 36s\n",
      "428:\tlearn: 2297.5430625\ttotal: 8m 17s\tremaining: 7m 35s\n",
      "429:\tlearn: 2296.8745193\ttotal: 8m 18s\tremaining: 7m 34s\n",
      "430:\tlearn: 2296.3701831\ttotal: 8m 19s\tremaining: 7m 33s\n",
      "431:\tlearn: 2295.8576114\ttotal: 8m 20s\tremaining: 7m 31s\n",
      "432:\tlearn: 2295.2292678\ttotal: 8m 21s\tremaining: 7m 30s\n",
      "433:\tlearn: 2294.7113354\ttotal: 8m 22s\tremaining: 7m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434:\tlearn: 2294.2085753\ttotal: 8m 24s\tremaining: 7m 28s\n",
      "435:\tlearn: 2293.5515980\ttotal: 8m 25s\tremaining: 7m 27s\n",
      "436:\tlearn: 2292.9660494\ttotal: 8m 26s\tremaining: 7m 26s\n",
      "437:\tlearn: 2292.3916880\ttotal: 8m 28s\tremaining: 7m 25s\n",
      "438:\tlearn: 2291.8143389\ttotal: 8m 29s\tremaining: 7m 24s\n",
      "439:\tlearn: 2291.7426237\ttotal: 8m 30s\tremaining: 7m 23s\n",
      "440:\tlearn: 2291.4532283\ttotal: 8m 31s\tremaining: 7m 22s\n",
      "441:\tlearn: 2290.8411969\ttotal: 8m 32s\tremaining: 7m 20s\n",
      "442:\tlearn: 2290.1722783\ttotal: 8m 34s\tremaining: 7m 19s\n",
      "443:\tlearn: 2289.7510817\ttotal: 8m 35s\tremaining: 7m 18s\n",
      "444:\tlearn: 2289.4187045\ttotal: 8m 36s\tremaining: 7m 17s\n",
      "445:\tlearn: 2288.9473627\ttotal: 8m 37s\tremaining: 7m 16s\n",
      "446:\tlearn: 2288.5895551\ttotal: 8m 38s\tremaining: 7m 15s\n",
      "447:\tlearn: 2288.1609791\ttotal: 8m 39s\tremaining: 7m 13s\n",
      "448:\tlearn: 2287.7648246\ttotal: 8m 41s\tremaining: 7m 12s\n",
      "449:\tlearn: 2287.1996434\ttotal: 8m 42s\tremaining: 7m 11s\n",
      "450:\tlearn: 2286.6900022\ttotal: 8m 43s\tremaining: 7m 10s\n",
      "451:\tlearn: 2286.2847934\ttotal: 8m 45s\tremaining: 7m 9s\n",
      "452:\tlearn: 2285.7476522\ttotal: 8m 46s\tremaining: 7m 8s\n",
      "453:\tlearn: 2285.1880891\ttotal: 8m 47s\tremaining: 7m 7s\n",
      "454:\tlearn: 2284.6421366\ttotal: 8m 48s\tremaining: 7m 6s\n",
      "455:\tlearn: 2284.1521505\ttotal: 8m 49s\tremaining: 7m 5s\n",
      "456:\tlearn: 2284.0521618\ttotal: 8m 50s\tremaining: 7m 4s\n",
      "457:\tlearn: 2283.3720346\ttotal: 8m 52s\tremaining: 7m 3s\n",
      "458:\tlearn: 2282.7755681\ttotal: 8m 53s\tremaining: 7m 1s\n",
      "459:\tlearn: 2282.1627896\ttotal: 8m 54s\tremaining: 7m\n",
      "460:\tlearn: 2281.6258922\ttotal: 8m 56s\tremaining: 6m 59s\n",
      "461:\tlearn: 2280.9142763\ttotal: 8m 57s\tremaining: 6m 58s\n",
      "462:\tlearn: 2280.6168544\ttotal: 8m 58s\tremaining: 6m 57s\n",
      "463:\tlearn: 2280.0389214\ttotal: 8m 59s\tremaining: 6m 56s\n",
      "464:\tlearn: 2279.6627856\ttotal: 9m\tremaining: 6m 55s\n",
      "465:\tlearn: 2279.1432521\ttotal: 9m 2s\tremaining: 6m 54s\n",
      "466:\tlearn: 2278.5228124\ttotal: 9m 3s\tremaining: 6m 52s\n",
      "467:\tlearn: 2277.9801249\ttotal: 9m 4s\tremaining: 6m 51s\n",
      "468:\tlearn: 2277.5523948\ttotal: 9m 5s\tremaining: 6m 50s\n",
      "469:\tlearn: 2277.0010472\ttotal: 9m 6s\tremaining: 6m 49s\n",
      "470:\tlearn: 2276.5808536\ttotal: 9m 7s\tremaining: 6m 48s\n",
      "471:\tlearn: 2276.0193696\ttotal: 9m 8s\tremaining: 6m 46s\n",
      "472:\tlearn: 2275.5232114\ttotal: 9m 9s\tremaining: 6m 45s\n",
      "473:\tlearn: 2275.0300929\ttotal: 9m 11s\tremaining: 6m 44s\n",
      "474:\tlearn: 2274.6013714\ttotal: 9m 12s\tremaining: 6m 43s\n",
      "475:\tlearn: 2273.9201119\ttotal: 9m 13s\tremaining: 6m 42s\n",
      "476:\tlearn: 2273.3276446\ttotal: 9m 14s\tremaining: 6m 41s\n",
      "477:\tlearn: 2272.6847613\ttotal: 9m 15s\tremaining: 6m 40s\n",
      "478:\tlearn: 2272.1810065\ttotal: 9m 17s\tremaining: 6m 38s\n",
      "479:\tlearn: 2271.6284882\ttotal: 9m 18s\tremaining: 6m 37s\n",
      "480:\tlearn: 2271.5033416\ttotal: 9m 19s\tremaining: 6m 36s\n",
      "481:\tlearn: 2271.2512125\ttotal: 9m 20s\tremaining: 6m 35s\n",
      "482:\tlearn: 2270.7973955\ttotal: 9m 21s\tremaining: 6m 34s\n",
      "483:\tlearn: 2270.5407504\ttotal: 9m 22s\tremaining: 6m 33s\n",
      "484:\tlearn: 2270.0447656\ttotal: 9m 23s\tremaining: 6m 31s\n",
      "485:\tlearn: 2269.8853012\ttotal: 9m 25s\tremaining: 6m 30s\n",
      "486:\tlearn: 2269.3427770\ttotal: 9m 26s\tremaining: 6m 29s\n",
      "487:\tlearn: 2268.5255117\ttotal: 9m 27s\tremaining: 6m 28s\n",
      "488:\tlearn: 2267.9286414\ttotal: 9m 28s\tremaining: 6m 27s\n",
      "489:\tlearn: 2267.5320096\ttotal: 9m 29s\tremaining: 6m 26s\n",
      "490:\tlearn: 2267.2964344\ttotal: 9m 30s\tremaining: 6m 24s\n",
      "491:\tlearn: 2266.9534621\ttotal: 9m 32s\tremaining: 6m 23s\n",
      "492:\tlearn: 2266.5095567\ttotal: 9m 33s\tremaining: 6m 22s\n",
      "493:\tlearn: 2266.1540341\ttotal: 9m 34s\tremaining: 6m 21s\n",
      "494:\tlearn: 2265.8578345\ttotal: 9m 35s\tremaining: 6m 20s\n",
      "495:\tlearn: 2265.7552560\ttotal: 9m 36s\tremaining: 6m 19s\n",
      "496:\tlearn: 2265.1149408\ttotal: 9m 38s\tremaining: 6m 18s\n",
      "497:\tlearn: 2264.7263034\ttotal: 9m 39s\tremaining: 6m 16s\n",
      "498:\tlearn: 2264.2024149\ttotal: 9m 40s\tremaining: 6m 15s\n",
      "499:\tlearn: 2263.7258796\ttotal: 9m 41s\tremaining: 6m 14s\n",
      "500:\tlearn: 2263.1542369\ttotal: 9m 42s\tremaining: 6m 13s\n",
      "501:\tlearn: 2262.8548272\ttotal: 9m 44s\tremaining: 6m 12s\n",
      "502:\tlearn: 2262.7400592\ttotal: 9m 44s\tremaining: 6m 10s\n",
      "503:\tlearn: 2262.1259786\ttotal: 9m 46s\tremaining: 6m 9s\n",
      "504:\tlearn: 2261.6042518\ttotal: 9m 47s\tremaining: 6m 8s\n",
      "505:\tlearn: 2261.2490441\ttotal: 9m 48s\tremaining: 6m 7s\n",
      "506:\tlearn: 2260.9210863\ttotal: 9m 49s\tremaining: 6m 6s\n",
      "507:\tlearn: 2260.4788672\ttotal: 9m 51s\tremaining: 6m 5s\n",
      "508:\tlearn: 2259.8041837\ttotal: 9m 52s\tremaining: 6m 4s\n",
      "509:\tlearn: 2259.2463625\ttotal: 9m 53s\tremaining: 6m 3s\n",
      "510:\tlearn: 2258.6482446\ttotal: 9m 54s\tremaining: 6m 1s\n",
      "511:\tlearn: 2258.5500472\ttotal: 9m 56s\tremaining: 6m\n",
      "512:\tlearn: 2258.3105136\ttotal: 9m 57s\tremaining: 5m 59s\n",
      "513:\tlearn: 2258.1142409\ttotal: 9m 58s\tremaining: 5m 58s\n",
      "514:\tlearn: 2257.5402552\ttotal: 9m 59s\tremaining: 5m 57s\n",
      "515:\tlearn: 2256.9996588\ttotal: 10m\tremaining: 5m 56s\n",
      "516:\tlearn: 2256.9127823\ttotal: 10m 1s\tremaining: 5m 55s\n",
      "517:\tlearn: 2256.3337766\ttotal: 10m 3s\tremaining: 5m 54s\n",
      "518:\tlearn: 2255.6905027\ttotal: 10m 4s\tremaining: 5m 52s\n",
      "519:\tlearn: 2255.2078785\ttotal: 10m 5s\tremaining: 5m 51s\n",
      "520:\tlearn: 2254.8819055\ttotal: 10m 6s\tremaining: 5m 50s\n",
      "521:\tlearn: 2253.9839735\ttotal: 10m 7s\tremaining: 5m 49s\n",
      "522:\tlearn: 2253.8936265\ttotal: 10m 7s\tremaining: 5m 47s\n",
      "523:\tlearn: 2253.4575638\ttotal: 10m 8s\tremaining: 5m 46s\n",
      "524:\tlearn: 2253.3966050\ttotal: 10m 9s\tremaining: 5m 45s\n",
      "525:\tlearn: 2252.8371607\ttotal: 10m 10s\tremaining: 5m 43s\n",
      "526:\tlearn: 2252.5439182\ttotal: 10m 11s\tremaining: 5m 42s\n",
      "527:\tlearn: 2251.9799222\ttotal: 10m 13s\tremaining: 5m 41s\n",
      "528:\tlearn: 2251.3535186\ttotal: 10m 14s\tremaining: 5m 40s\n",
      "529:\tlearn: 2250.9786358\ttotal: 10m 15s\tremaining: 5m 39s\n",
      "530:\tlearn: 2250.6915596\ttotal: 10m 16s\tremaining: 5m 37s\n",
      "531:\tlearn: 2250.1876485\ttotal: 10m 17s\tremaining: 5m 36s\n",
      "532:\tlearn: 2249.8546335\ttotal: 10m 19s\tremaining: 5m 35s\n",
      "533:\tlearn: 2249.4361022\ttotal: 10m 20s\tremaining: 5m 34s\n",
      "534:\tlearn: 2249.2325769\ttotal: 10m 21s\tremaining: 5m 33s\n",
      "535:\tlearn: 2248.5942925\ttotal: 10m 22s\tremaining: 5m 32s\n",
      "536:\tlearn: 2248.0525682\ttotal: 10m 23s\tremaining: 5m 30s\n",
      "537:\tlearn: 2247.5698541\ttotal: 10m 24s\tremaining: 5m 29s\n",
      "538:\tlearn: 2247.0891440\ttotal: 10m 26s\tremaining: 5m 28s\n",
      "539:\tlearn: 2246.5448363\ttotal: 10m 26s\tremaining: 5m 27s\n",
      "540:\tlearn: 2246.1740664\ttotal: 10m 28s\tremaining: 5m 26s\n",
      "541:\tlearn: 2245.7391822\ttotal: 10m 29s\tremaining: 5m 25s\n",
      "542:\tlearn: 2245.1837570\ttotal: 10m 30s\tremaining: 5m 23s\n",
      "543:\tlearn: 2244.8985878\ttotal: 10m 31s\tremaining: 5m 22s\n",
      "544:\tlearn: 2244.3923362\ttotal: 10m 32s\tremaining: 5m 21s\n",
      "545:\tlearn: 2243.8949452\ttotal: 10m 34s\tremaining: 5m 20s\n",
      "546:\tlearn: 2243.5109331\ttotal: 10m 35s\tremaining: 5m 19s\n",
      "547:\tlearn: 2243.2191186\ttotal: 10m 36s\tremaining: 5m 18s\n",
      "548:\tlearn: 2242.6227991\ttotal: 10m 37s\tremaining: 5m 17s\n",
      "549:\tlearn: 2242.3914648\ttotal: 10m 39s\tremaining: 5m 16s\n",
      "550:\tlearn: 2241.8088135\ttotal: 10m 39s\tremaining: 5m 14s\n",
      "551:\tlearn: 2241.3288574\ttotal: 10m 41s\tremaining: 5m 13s\n",
      "552:\tlearn: 2240.7329079\ttotal: 10m 42s\tremaining: 5m 12s\n",
      "553:\tlearn: 2240.1879098\ttotal: 10m 43s\tremaining: 5m 11s\n",
      "554:\tlearn: 2239.6680592\ttotal: 10m 44s\tremaining: 5m 10s\n",
      "555:\tlearn: 2239.1880984\ttotal: 10m 45s\tremaining: 5m 8s\n",
      "556:\tlearn: 2238.8172900\ttotal: 10m 46s\tremaining: 5m 7s\n",
      "557:\tlearn: 2238.5469426\ttotal: 10m 48s\tremaining: 5m 6s\n",
      "558:\tlearn: 2238.0139673\ttotal: 10m 49s\tremaining: 5m 5s\n",
      "559:\tlearn: 2237.6307781\ttotal: 10m 50s\tremaining: 5m 4s\n",
      "560:\tlearn: 2237.4234770\ttotal: 10m 51s\tremaining: 5m 3s\n",
      "561:\tlearn: 2236.8469414\ttotal: 10m 52s\tremaining: 5m 2s\n",
      "562:\tlearn: 2236.4223234\ttotal: 10m 53s\tremaining: 5m\n",
      "563:\tlearn: 2236.0456699\ttotal: 10m 55s\tremaining: 4m 59s\n",
      "564:\tlearn: 2235.6226317\ttotal: 10m 56s\tremaining: 4m 58s\n",
      "565:\tlearn: 2235.5105921\ttotal: 10m 57s\tremaining: 4m 57s\n",
      "566:\tlearn: 2234.8974563\ttotal: 10m 58s\tremaining: 4m 56s\n",
      "567:\tlearn: 2234.3159004\ttotal: 10m 59s\tremaining: 4m 55s\n",
      "568:\tlearn: 2233.7843655\ttotal: 11m 1s\tremaining: 4m 53s\n",
      "569:\tlearn: 2233.4410500\ttotal: 11m 2s\tremaining: 4m 52s\n",
      "570:\tlearn: 2233.0107197\ttotal: 11m 3s\tremaining: 4m 51s\n",
      "571:\tlearn: 2232.7733212\ttotal: 11m 4s\tremaining: 4m 50s\n",
      "572:\tlearn: 2232.3063137\ttotal: 11m 5s\tremaining: 4m 49s\n",
      "573:\tlearn: 2231.7261197\ttotal: 11m 7s\tremaining: 4m 48s\n",
      "574:\tlearn: 2231.5603024\ttotal: 11m 8s\tremaining: 4m 47s\n",
      "575:\tlearn: 2231.0947076\ttotal: 11m 9s\tremaining: 4m 45s\n",
      "576:\tlearn: 2230.5764507\ttotal: 11m 10s\tremaining: 4m 44s\n",
      "577:\tlearn: 2230.2338352\ttotal: 11m 11s\tremaining: 4m 43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578:\tlearn: 2229.8939961\ttotal: 11m 13s\tremaining: 4m 42s\n",
      "579:\tlearn: 2229.5720827\ttotal: 11m 14s\tremaining: 4m 41s\n",
      "580:\tlearn: 2229.0496808\ttotal: 11m 15s\tremaining: 4m 40s\n",
      "581:\tlearn: 2228.6510092\ttotal: 11m 16s\tremaining: 4m 39s\n",
      "582:\tlearn: 2228.5374875\ttotal: 11m 17s\tremaining: 4m 37s\n",
      "583:\tlearn: 2228.2289798\ttotal: 11m 19s\tremaining: 4m 36s\n",
      "584:\tlearn: 2227.7755091\ttotal: 11m 20s\tremaining: 4m 35s\n",
      "585:\tlearn: 2227.2690354\ttotal: 11m 21s\tremaining: 4m 34s\n",
      "586:\tlearn: 2226.7428341\ttotal: 11m 23s\tremaining: 4m 33s\n",
      "587:\tlearn: 2226.2966845\ttotal: 11m 24s\tremaining: 4m 32s\n",
      "588:\tlearn: 2225.8256335\ttotal: 11m 25s\tremaining: 4m 31s\n",
      "589:\tlearn: 2225.2933895\ttotal: 11m 26s\tremaining: 4m 29s\n",
      "590:\tlearn: 2224.7504574\ttotal: 11m 27s\tremaining: 4m 28s\n",
      "591:\tlearn: 2224.1859834\ttotal: 11m 29s\tremaining: 4m 27s\n",
      "592:\tlearn: 2223.6248809\ttotal: 11m 30s\tremaining: 4m 26s\n",
      "593:\tlearn: 2223.1428642\ttotal: 11m 31s\tremaining: 4m 25s\n",
      "594:\tlearn: 2222.7574627\ttotal: 11m 32s\tremaining: 4m 24s\n",
      "595:\tlearn: 2222.2489793\ttotal: 11m 33s\tremaining: 4m 23s\n",
      "596:\tlearn: 2222.0140192\ttotal: 11m 35s\tremaining: 4m 21s\n",
      "597:\tlearn: 2221.7272527\ttotal: 11m 36s\tremaining: 4m 20s\n",
      "598:\tlearn: 2221.2878624\ttotal: 11m 37s\tremaining: 4m 19s\n",
      "599:\tlearn: 2220.9161810\ttotal: 11m 38s\tremaining: 4m 18s\n",
      "600:\tlearn: 2220.6123048\ttotal: 11m 39s\tremaining: 4m 17s\n",
      "601:\tlearn: 2220.0881584\ttotal: 11m 40s\tremaining: 4m 16s\n",
      "602:\tlearn: 2219.8067025\ttotal: 11m 41s\tremaining: 4m 14s\n",
      "603:\tlearn: 2219.2128051\ttotal: 11m 43s\tremaining: 4m 13s\n",
      "604:\tlearn: 2219.1447734\ttotal: 11m 43s\tremaining: 4m 12s\n",
      "605:\tlearn: 2219.0970160\ttotal: 11m 45s\tremaining: 4m 11s\n",
      "606:\tlearn: 2218.5921393\ttotal: 11m 46s\tremaining: 4m 10s\n",
      "607:\tlearn: 2218.5592455\ttotal: 11m 46s\tremaining: 4m 8s\n",
      "608:\tlearn: 2218.3789352\ttotal: 11m 47s\tremaining: 4m 7s\n",
      "609:\tlearn: 2217.7847389\ttotal: 11m 49s\tremaining: 4m 6s\n",
      "610:\tlearn: 2217.5924873\ttotal: 11m 50s\tremaining: 4m 5s\n",
      "611:\tlearn: 2217.5646935\ttotal: 11m 51s\tremaining: 4m 4s\n",
      "612:\tlearn: 2216.9613254\ttotal: 11m 52s\tremaining: 4m 3s\n",
      "613:\tlearn: 2216.4239594\ttotal: 11m 54s\tremaining: 4m 1s\n",
      "614:\tlearn: 2216.0741392\ttotal: 11m 55s\tremaining: 4m\n",
      "615:\tlearn: 2215.8632035\ttotal: 11m 56s\tremaining: 3m 59s\n",
      "616:\tlearn: 2215.5250325\ttotal: 11m 57s\tremaining: 3m 58s\n",
      "617:\tlearn: 2215.1537210\ttotal: 11m 58s\tremaining: 3m 57s\n",
      "618:\tlearn: 2214.8227049\ttotal: 12m\tremaining: 3m 56s\n",
      "619:\tlearn: 2214.3518158\ttotal: 12m 1s\tremaining: 3m 55s\n",
      "620:\tlearn: 2213.6944727\ttotal: 12m 2s\tremaining: 3m 53s\n",
      "621:\tlearn: 2213.3401559\ttotal: 12m 3s\tremaining: 3m 52s\n",
      "622:\tlearn: 2212.7546697\ttotal: 12m 4s\tremaining: 3m 51s\n",
      "623:\tlearn: 2212.3502688\ttotal: 12m 5s\tremaining: 3m 50s\n",
      "624:\tlearn: 2211.8907895\ttotal: 12m 6s\tremaining: 3m 49s\n",
      "625:\tlearn: 2211.3179490\ttotal: 12m 7s\tremaining: 3m 47s\n",
      "626:\tlearn: 2211.1205784\ttotal: 12m 9s\tremaining: 3m 46s\n",
      "627:\tlearn: 2210.8614061\ttotal: 12m 9s\tremaining: 3m 45s\n",
      "628:\tlearn: 2210.3596867\ttotal: 12m 11s\tremaining: 3m 44s\n",
      "629:\tlearn: 2210.2203868\ttotal: 12m 12s\tremaining: 3m 43s\n",
      "630:\tlearn: 2209.7981697\ttotal: 12m 13s\tremaining: 3m 42s\n",
      "631:\tlearn: 2209.5368515\ttotal: 12m 14s\tremaining: 3m 40s\n",
      "632:\tlearn: 2209.0967720\ttotal: 12m 16s\tremaining: 3m 39s\n",
      "633:\tlearn: 2208.8836940\ttotal: 12m 17s\tremaining: 3m 38s\n",
      "634:\tlearn: 2208.4709788\ttotal: 12m 18s\tremaining: 3m 37s\n",
      "635:\tlearn: 2207.9487530\ttotal: 12m 19s\tremaining: 3m 36s\n",
      "636:\tlearn: 2207.4251595\ttotal: 12m 20s\tremaining: 3m 35s\n",
      "637:\tlearn: 2206.9478415\ttotal: 12m 22s\tremaining: 3m 34s\n",
      "638:\tlearn: 2206.6083074\ttotal: 12m 23s\tremaining: 3m 32s\n",
      "639:\tlearn: 2206.5099010\ttotal: 12m 24s\tremaining: 3m 31s\n",
      "640:\tlearn: 2206.0108855\ttotal: 12m 25s\tremaining: 3m 30s\n",
      "641:\tlearn: 2205.6233445\ttotal: 12m 27s\tremaining: 3m 29s\n",
      "642:\tlearn: 2205.3172062\ttotal: 12m 28s\tremaining: 3m 28s\n",
      "643:\tlearn: 2205.2248145\ttotal: 12m 29s\tremaining: 3m 27s\n",
      "644:\tlearn: 2204.9594124\ttotal: 12m 30s\tremaining: 3m 26s\n",
      "645:\tlearn: 2204.6495153\ttotal: 12m 31s\tremaining: 3m 24s\n",
      "646:\tlearn: 2204.2547039\ttotal: 12m 33s\tremaining: 3m 23s\n",
      "647:\tlearn: 2203.6405860\ttotal: 12m 34s\tremaining: 3m 22s\n",
      "648:\tlearn: 2203.4400148\ttotal: 12m 35s\tremaining: 3m 21s\n",
      "649:\tlearn: 2203.3060489\ttotal: 12m 36s\tremaining: 3m 20s\n",
      "650:\tlearn: 2202.7514520\ttotal: 12m 38s\tremaining: 3m 19s\n",
      "651:\tlearn: 2202.2050938\ttotal: 12m 39s\tremaining: 3m 17s\n",
      "652:\tlearn: 2201.8069749\ttotal: 12m 40s\tremaining: 3m 16s\n",
      "653:\tlearn: 2201.3550733\ttotal: 12m 41s\tremaining: 3m 15s\n",
      "654:\tlearn: 2200.9716590\ttotal: 12m 42s\tremaining: 3m 14s\n",
      "655:\tlearn: 2200.6585299\ttotal: 12m 43s\tremaining: 3m 13s\n",
      "656:\tlearn: 2200.2529807\ttotal: 12m 45s\tremaining: 3m 12s\n",
      "657:\tlearn: 2199.7346791\ttotal: 12m 46s\tremaining: 3m 11s\n",
      "658:\tlearn: 2199.2967017\ttotal: 12m 47s\tremaining: 3m 9s\n",
      "659:\tlearn: 2199.0359356\ttotal: 12m 48s\tremaining: 3m 8s\n",
      "660:\tlearn: 2198.5638061\ttotal: 12m 49s\tremaining: 3m 7s\n",
      "661:\tlearn: 2198.0742672\ttotal: 12m 51s\tremaining: 3m 6s\n",
      "662:\tlearn: 2197.6872480\ttotal: 12m 52s\tremaining: 3m 5s\n",
      "663:\tlearn: 2197.1161193\ttotal: 12m 53s\tremaining: 3m 4s\n",
      "664:\tlearn: 2196.7002007\ttotal: 12m 54s\tremaining: 3m 2s\n",
      "665:\tlearn: 2196.2682432\ttotal: 12m 55s\tremaining: 3m 1s\n",
      "666:\tlearn: 2195.9023217\ttotal: 12m 57s\tremaining: 3m\n",
      "667:\tlearn: 2195.4563046\ttotal: 12m 58s\tremaining: 2m 59s\n",
      "668:\tlearn: 2195.0040956\ttotal: 12m 59s\tremaining: 2m 58s\n",
      "669:\tlearn: 2194.6214026\ttotal: 13m\tremaining: 2m 57s\n",
      "670:\tlearn: 2194.3487986\ttotal: 13m 2s\tremaining: 2m 55s\n",
      "671:\tlearn: 2193.8555253\ttotal: 13m 3s\tremaining: 2m 54s\n",
      "672:\tlearn: 2193.5813887\ttotal: 13m 4s\tremaining: 2m 53s\n",
      "673:\tlearn: 2193.1626442\ttotal: 13m 5s\tremaining: 2m 52s\n",
      "674:\tlearn: 2192.6167229\ttotal: 13m 6s\tremaining: 2m 51s\n",
      "675:\tlearn: 2192.1225189\ttotal: 13m 7s\tremaining: 2m 50s\n",
      "676:\tlearn: 2191.8876595\ttotal: 13m 9s\tremaining: 2m 48s\n",
      "677:\tlearn: 2191.3692064\ttotal: 13m 10s\tremaining: 2m 47s\n",
      "678:\tlearn: 2190.9081849\ttotal: 13m 11s\tremaining: 2m 46s\n",
      "679:\tlearn: 2190.5507701\ttotal: 13m 12s\tremaining: 2m 45s\n",
      "680:\tlearn: 2190.1382651\ttotal: 13m 13s\tremaining: 2m 44s\n",
      "681:\tlearn: 2189.6267444\ttotal: 13m 15s\tremaining: 2m 43s\n",
      "682:\tlearn: 2189.1612631\ttotal: 13m 16s\tremaining: 2m 42s\n",
      "683:\tlearn: 2188.6290611\ttotal: 13m 17s\tremaining: 2m 40s\n",
      "684:\tlearn: 2188.0744144\ttotal: 13m 18s\tremaining: 2m 39s\n",
      "685:\tlearn: 2187.6093889\ttotal: 13m 19s\tremaining: 2m 38s\n",
      "686:\tlearn: 2187.2140451\ttotal: 13m 20s\tremaining: 2m 37s\n",
      "687:\tlearn: 2186.7392047\ttotal: 13m 21s\tremaining: 2m 36s\n",
      "688:\tlearn: 2186.2948574\ttotal: 13m 22s\tremaining: 2m 34s\n",
      "689:\tlearn: 2185.9531999\ttotal: 13m 23s\tremaining: 2m 33s\n",
      "690:\tlearn: 2185.4552363\ttotal: 13m 24s\tremaining: 2m 32s\n",
      "691:\tlearn: 2185.1704271\ttotal: 13m 25s\tremaining: 2m 31s\n",
      "692:\tlearn: 2184.7932959\ttotal: 13m 26s\tremaining: 2m 30s\n",
      "693:\tlearn: 2184.2593419\ttotal: 13m 27s\tremaining: 2m 29s\n",
      "694:\tlearn: 2183.8994399\ttotal: 13m 29s\tremaining: 2m 27s\n",
      "695:\tlearn: 2183.8570956\ttotal: 13m 29s\tremaining: 2m 26s\n",
      "696:\tlearn: 2183.4442620\ttotal: 13m 30s\tremaining: 2m 25s\n",
      "697:\tlearn: 2183.1269444\ttotal: 13m 31s\tremaining: 2m 24s\n",
      "698:\tlearn: 2182.6866433\ttotal: 13m 32s\tremaining: 2m 23s\n",
      "699:\tlearn: 2182.1824409\ttotal: 13m 34s\tremaining: 2m 21s\n",
      "700:\tlearn: 2181.7324908\ttotal: 13m 35s\tremaining: 2m 20s\n",
      "701:\tlearn: 2181.5238102\ttotal: 13m 36s\tremaining: 2m 19s\n",
      "702:\tlearn: 2180.9599210\ttotal: 13m 37s\tremaining: 2m 18s\n",
      "703:\tlearn: 2180.6836809\ttotal: 13m 38s\tremaining: 2m 17s\n",
      "704:\tlearn: 2180.2221388\ttotal: 13m 39s\tremaining: 2m 16s\n",
      "705:\tlearn: 2180.0543603\ttotal: 13m 40s\tremaining: 2m 14s\n",
      "706:\tlearn: 2179.8802486\ttotal: 13m 41s\tremaining: 2m 13s\n",
      "707:\tlearn: 2179.4355693\ttotal: 13m 42s\tremaining: 2m 12s\n",
      "708:\tlearn: 2179.0276927\ttotal: 13m 43s\tremaining: 2m 11s\n",
      "709:\tlearn: 2178.5427687\ttotal: 13m 44s\tremaining: 2m 10s\n",
      "710:\tlearn: 2178.0714267\ttotal: 13m 45s\tremaining: 2m 8s\n",
      "711:\tlearn: 2177.7149442\ttotal: 13m 46s\tremaining: 2m 7s\n",
      "712:\tlearn: 2177.3460635\ttotal: 13m 47s\tremaining: 2m 6s\n",
      "713:\tlearn: 2176.7917918\ttotal: 13m 48s\tremaining: 2m 5s\n",
      "714:\tlearn: 2176.2831938\ttotal: 13m 49s\tremaining: 2m 4s\n",
      "715:\tlearn: 2175.9172434\ttotal: 13m 51s\tremaining: 2m 3s\n",
      "716:\tlearn: 2175.4264290\ttotal: 13m 52s\tremaining: 2m 1s\n",
      "717:\tlearn: 2174.9192149\ttotal: 13m 53s\tremaining: 2m\n",
      "718:\tlearn: 2174.4394456\ttotal: 13m 54s\tremaining: 1m 59s\n",
      "719:\tlearn: 2173.9053207\ttotal: 13m 55s\tremaining: 1m 58s\n",
      "720:\tlearn: 2173.4339271\ttotal: 13m 56s\tremaining: 1m 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721:\tlearn: 2172.9566788\ttotal: 13m 58s\tremaining: 1m 56s\n",
      "722:\tlearn: 2172.9285620\ttotal: 13m 59s\tremaining: 1m 54s\n",
      "723:\tlearn: 2172.5666753\ttotal: 14m\tremaining: 1m 53s\n",
      "724:\tlearn: 2172.3451173\ttotal: 14m 1s\tremaining: 1m 52s\n",
      "725:\tlearn: 2171.9062360\ttotal: 14m 3s\tremaining: 1m 51s\n",
      "726:\tlearn: 2171.4290182\ttotal: 14m 4s\tremaining: 1m 50s\n",
      "727:\tlearn: 2171.0999134\ttotal: 14m 5s\tremaining: 1m 49s\n",
      "728:\tlearn: 2170.7217093\ttotal: 14m 6s\tremaining: 1m 48s\n",
      "729:\tlearn: 2170.3427057\ttotal: 14m 8s\tremaining: 1m 46s\n",
      "730:\tlearn: 2170.0527616\ttotal: 14m 9s\tremaining: 1m 45s\n",
      "731:\tlearn: 2169.5896925\ttotal: 14m 10s\tremaining: 1m 44s\n",
      "732:\tlearn: 2169.4469558\ttotal: 14m 12s\tremaining: 1m 43s\n",
      "733:\tlearn: 2168.9042861\ttotal: 14m 13s\tremaining: 1m 42s\n",
      "734:\tlearn: 2168.7494548\ttotal: 14m 14s\tremaining: 1m 41s\n",
      "735:\tlearn: 2168.2443640\ttotal: 14m 15s\tremaining: 1m 40s\n",
      "736:\tlearn: 2167.9006309\ttotal: 14m 17s\tremaining: 1m 38s\n",
      "737:\tlearn: 2167.4646659\ttotal: 14m 18s\tremaining: 1m 37s\n",
      "738:\tlearn: 2167.0313123\ttotal: 14m 19s\tremaining: 1m 36s\n",
      "739:\tlearn: 2166.6797106\ttotal: 14m 20s\tremaining: 1m 35s\n",
      "740:\tlearn: 2166.2493964\ttotal: 14m 22s\tremaining: 1m 34s\n",
      "741:\tlearn: 2165.7457320\ttotal: 14m 23s\tremaining: 1m 33s\n",
      "742:\tlearn: 2165.3008225\ttotal: 14m 24s\tremaining: 1m 31s\n",
      "743:\tlearn: 2164.9091192\ttotal: 14m 26s\tremaining: 1m 30s\n",
      "744:\tlearn: 2164.4745775\ttotal: 14m 27s\tremaining: 1m 29s\n",
      "745:\tlearn: 2164.3315809\ttotal: 14m 28s\tremaining: 1m 28s\n",
      "746:\tlearn: 2163.9610214\ttotal: 14m 29s\tremaining: 1m 27s\n",
      "747:\tlearn: 2163.5681524\ttotal: 14m 30s\tremaining: 1m 26s\n",
      "748:\tlearn: 2163.5245721\ttotal: 14m 31s\tremaining: 1m 24s\n",
      "749:\tlearn: 2163.1653286\ttotal: 14m 33s\tremaining: 1m 23s\n",
      "750:\tlearn: 2162.8409381\ttotal: 14m 34s\tremaining: 1m 22s\n",
      "751:\tlearn: 2162.3745690\ttotal: 14m 35s\tremaining: 1m 21s\n",
      "752:\tlearn: 2162.1232829\ttotal: 14m 36s\tremaining: 1m 20s\n",
      "753:\tlearn: 2161.6757124\ttotal: 14m 38s\tremaining: 1m 19s\n",
      "754:\tlearn: 2161.3977452\ttotal: 14m 39s\tremaining: 1m 18s\n",
      "755:\tlearn: 2161.1713191\ttotal: 14m 40s\tremaining: 1m 16s\n",
      "756:\tlearn: 2160.5977569\ttotal: 14m 41s\tremaining: 1m 15s\n",
      "757:\tlearn: 2160.1741567\ttotal: 14m 43s\tremaining: 1m 14s\n",
      "758:\tlearn: 2159.7044470\ttotal: 14m 44s\tremaining: 1m 13s\n",
      "759:\tlearn: 2159.2688154\ttotal: 14m 45s\tremaining: 1m 12s\n",
      "760:\tlearn: 2158.8739339\ttotal: 14m 46s\tremaining: 1m 11s\n",
      "761:\tlearn: 2158.4368404\ttotal: 14m 48s\tremaining: 1m 9s\n",
      "762:\tlearn: 2158.0702366\ttotal: 14m 49s\tremaining: 1m 8s\n",
      "763:\tlearn: 2157.7565141\ttotal: 14m 50s\tremaining: 1m 7s\n",
      "764:\tlearn: 2157.6034098\ttotal: 14m 51s\tremaining: 1m 6s\n",
      "765:\tlearn: 2157.1604065\ttotal: 14m 52s\tremaining: 1m 5s\n",
      "766:\tlearn: 2156.6681861\ttotal: 14m 54s\tremaining: 1m 4s\n",
      "767:\tlearn: 2156.2632159\ttotal: 14m 55s\tremaining: 1m 2s\n",
      "768:\tlearn: 2155.8416321\ttotal: 14m 56s\tremaining: 1m 1s\n",
      "769:\tlearn: 2155.6055048\ttotal: 14m 57s\tremaining: 1m\n",
      "770:\tlearn: 2155.2055934\ttotal: 14m 58s\tremaining: 59.5s\n",
      "771:\tlearn: 2154.7982531\ttotal: 14m 59s\tremaining: 58.3s\n",
      "772:\tlearn: 2154.3029735\ttotal: 15m\tremaining: 57.1s\n",
      "773:\tlearn: 2154.1332166\ttotal: 15m 1s\tremaining: 55.9s\n",
      "774:\tlearn: 2153.6678711\ttotal: 15m 3s\tremaining: 54.8s\n",
      "775:\tlearn: 2153.1715166\ttotal: 15m 4s\tremaining: 53.6s\n",
      "776:\tlearn: 2152.8026920\ttotal: 15m 5s\tremaining: 52.5s\n",
      "777:\tlearn: 2152.3743466\ttotal: 15m 6s\tremaining: 51.3s\n",
      "778:\tlearn: 2151.9565012\ttotal: 15m 8s\tremaining: 50.1s\n",
      "779:\tlearn: 2151.6182485\ttotal: 15m 9s\tremaining: 49s\n",
      "780:\tlearn: 2151.3640792\ttotal: 15m 10s\tremaining: 47.8s\n",
      "781:\tlearn: 2151.0767710\ttotal: 15m 11s\tremaining: 46.6s\n",
      "782:\tlearn: 2150.4893442\ttotal: 15m 12s\tremaining: 45.5s\n",
      "783:\tlearn: 2149.9998853\ttotal: 15m 13s\tremaining: 44.3s\n",
      "784:\tlearn: 2149.7492800\ttotal: 15m 14s\tremaining: 43.1s\n",
      "785:\tlearn: 2149.4414189\ttotal: 15m 16s\tremaining: 42s\n",
      "786:\tlearn: 2149.0082940\ttotal: 15m 17s\tremaining: 40.8s\n",
      "787:\tlearn: 2148.8617054\ttotal: 15m 18s\tremaining: 39.6s\n",
      "788:\tlearn: 2148.4045745\ttotal: 15m 20s\tremaining: 38.5s\n",
      "789:\tlearn: 2147.8651447\ttotal: 15m 21s\tremaining: 37.3s\n",
      "790:\tlearn: 2147.5750520\ttotal: 15m 22s\tremaining: 36.1s\n",
      "791:\tlearn: 2147.2195530\ttotal: 15m 23s\tremaining: 35s\n",
      "792:\tlearn: 2146.9626312\ttotal: 15m 24s\tremaining: 33.8s\n",
      "793:\tlearn: 2146.7151322\ttotal: 15m 25s\tremaining: 32.6s\n",
      "794:\tlearn: 2146.1903278\ttotal: 15m 26s\tremaining: 31.5s\n",
      "795:\tlearn: 2145.8228943\ttotal: 15m 27s\tremaining: 30.3s\n",
      "796:\tlearn: 2145.3395043\ttotal: 15m 29s\tremaining: 29.1s\n",
      "797:\tlearn: 2144.9524189\ttotal: 15m 30s\tremaining: 28s\n",
      "798:\tlearn: 2144.4969110\ttotal: 15m 31s\tremaining: 26.8s\n",
      "799:\tlearn: 2144.1823238\ttotal: 15m 32s\tremaining: 25.6s\n",
      "800:\tlearn: 2143.7365696\ttotal: 15m 33s\tremaining: 24.5s\n",
      "801:\tlearn: 2143.7343113\ttotal: 15m 33s\tremaining: 23.3s\n",
      "802:\tlearn: 2143.4515438\ttotal: 15m 35s\tremaining: 22.1s\n",
      "803:\tlearn: 2143.0733602\ttotal: 15m 36s\tremaining: 21s\n",
      "804:\tlearn: 2142.9576126\ttotal: 15m 37s\tremaining: 19.8s\n",
      "805:\tlearn: 2142.5400709\ttotal: 15m 38s\tremaining: 18.6s\n",
      "806:\tlearn: 2142.2361367\ttotal: 15m 40s\tremaining: 17.5s\n",
      "807:\tlearn: 2141.8897179\ttotal: 15m 41s\tremaining: 16.3s\n",
      "808:\tlearn: 2141.6062168\ttotal: 15m 42s\tremaining: 15.1s\n",
      "809:\tlearn: 2141.1936514\ttotal: 15m 43s\tremaining: 14s\n",
      "810:\tlearn: 2140.8771001\ttotal: 15m 44s\tremaining: 12.8s\n",
      "811:\tlearn: 2140.8485605\ttotal: 15m 45s\tremaining: 11.6s\n",
      "812:\tlearn: 2140.4826997\ttotal: 15m 47s\tremaining: 10.5s\n",
      "813:\tlearn: 2140.1473712\ttotal: 15m 48s\tremaining: 9.32s\n",
      "814:\tlearn: 2139.6966180\ttotal: 15m 49s\tremaining: 8.16s\n",
      "815:\tlearn: 2139.3873554\ttotal: 15m 50s\tremaining: 6.99s\n",
      "816:\tlearn: 2139.0057997\ttotal: 15m 52s\tremaining: 5.83s\n",
      "817:\tlearn: 2138.5477676\ttotal: 15m 53s\tremaining: 4.66s\n",
      "818:\tlearn: 2138.1396773\ttotal: 15m 54s\tremaining: 3.5s\n",
      "819:\tlearn: 2138.1173164\ttotal: 15m 55s\tremaining: 2.33s\n",
      "820:\tlearn: 2137.7022898\ttotal: 15m 57s\tremaining: 1.17s\n",
      "821:\tlearn: 2137.6680281\ttotal: 15m 58s\tremaining: 0us\n",
      "RMSE score is: 2445.138292942089\n",
      "Wall time: 16min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'max_depth': 16, 'n_estimators': 822, 'learning_rate': 0.34579951469275394, 'rsm': 0.255416100953266, 'reg_lambda': 860}\n",
    "cat = CatBoostRegressor(**params)\n",
    "cat.fit(X_trn, y_trn)\n",
    "preds = cat.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "print(f'RMSE score is: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 23:30:57,621] A new study created in memory with name: no-name-b9a14af7-9a2f-4ef7-be44-c49e593fda9a\n",
      "[I 2020-10-08 23:35:39,780] Trial 0 finished with value: 2464.109824128356 and parameters: {'max_depth': 13, 'n_estimators': 1059, 'learning_rate': 0.7436704297351775, 'rsm': 0.636459404703763, 'reg_lambda': 708}. Best is trial 0 with value: 2464.109824128356.\n",
      "[I 2020-10-08 23:36:09,793] Trial 1 finished with value: 2460.4662309121377 and parameters: {'max_depth': 8, 'n_estimators': 509, 'learning_rate': 0.6612073271073751, 'rsm': 0.44209971949050286, 'reg_lambda': 600}. Best is trial 1 with value: 2460.4662309121377.\n",
      "[I 2020-10-08 23:36:59,288] Trial 2 finished with value: 2466.9949993602977 and parameters: {'max_depth': 7, 'n_estimators': 972, 'learning_rate': 0.9672964844509263, 'rsm': 0.4412629517549421, 'reg_lambda': 487}. Best is trial 1 with value: 2460.4662309121377.\n",
      "[I 2020-10-08 23:37:33,918] Trial 3 finished with value: 2456.811854562535 and parameters: {'max_depth': 8, 'n_estimators': 587, 'learning_rate': 0.5319794551375516, 'rsm': 0.4495784685297385, 'reg_lambda': 538}. Best is trial 3 with value: 2456.811854562535.\n",
      "[I 2020-10-08 23:39:04,206] Trial 4 finished with value: 2503.4069378246663 and parameters: {'max_depth': 14, 'n_estimators': 572, 'learning_rate': 0.17841636973138664, 'rsm': 0.1179943737218899, 'reg_lambda': 756}. Best is trial 3 with value: 2456.811854562535.\n",
      "[I 2020-10-08 23:40:01,675] Trial 5 finished with value: 2453.1856551890173 and parameters: {'max_depth': 6, 'n_estimators': 1347, 'learning_rate': 0.8830109334221372, 'rsm': 0.9709703245871599, 'reg_lambda': 985}. Best is trial 5 with value: 2453.1856551890173.\n",
      "[I 2020-10-08 23:40:36,393] Trial 6 finished with value: 2564.9792591503856 and parameters: {'max_depth': 2, 'n_estimators': 1255, 'learning_rate': 0.5684297315960843, 'rsm': 0.7042027818058747, 'reg_lambda': 424}. Best is trial 5 with value: 2453.1856551890173.\n",
      "[I 2020-10-08 23:41:10,098] Trial 7 finished with value: 2721.0569929146227 and parameters: {'max_depth': 1, 'n_estimators': 1461, 'learning_rate': 0.22901795866814179, 'rsm': 0.9407553361741297, 'reg_lambda': 544}. Best is trial 5 with value: 2453.1856551890173.\n",
      "[I 2020-10-08 23:42:08,515] Trial 8 finished with value: 2447.9830461728293 and parameters: {'max_depth': 11, 'n_estimators': 744, 'learning_rate': 0.5262403774119917, 'rsm': 0.2658357855608164, 'reg_lambda': 883}. Best is trial 8 with value: 2447.9830461728293.\n",
      "[I 2020-10-08 23:42:32,840] Trial 9 finished with value: 2485.3112219070536 and parameters: {'max_depth': 8, 'n_estimators': 528, 'learning_rate': 0.6115905539817836, 'rsm': 0.11672292238835608, 'reg_lambda': 54}. Best is trial 8 with value: 2447.9830461728293.\n",
      "[I 2020-10-08 23:44:05,966] Trial 10 finished with value: 2447.207459783211 and parameters: {'max_depth': 12, 'n_estimators': 803, 'learning_rate': 0.39314966076443675, 'rsm': 0.2716935508894019, 'reg_lambda': 969}. Best is trial 10 with value: 2447.207459783211.\n",
      "[I 2020-10-08 23:45:33,941] Trial 11 finished with value: 2449.857020684218 and parameters: {'max_depth': 12, 'n_estimators': 806, 'learning_rate': 0.3731216024841598, 'rsm': 0.24006520582471533, 'reg_lambda': 988}. Best is trial 10 with value: 2447.207459783211.\n",
      "[I 2020-10-09 00:01:18,938] Trial 12 finished with value: 2444.093498761047 and parameters: {'max_depth': 16, 'n_estimators': 785, 'learning_rate': 0.36470277717448774, 'rsm': 0.265567266430082, 'reg_lambda': 867}. Best is trial 12 with value: 2444.093498761047.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-d99961fa91b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mcat_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                 self._optimize_sequential(\n\u001b[1;32m--> 328\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m                 )\n\u001b[0;32m    330\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    724\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 726\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    753\u001b[0m     ) -> None:\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-d99961fa91b1>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4838\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4839\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4840\u001b[1;33m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4842\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1803\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1805\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1806\u001b[0m             )\n\u001b[0;32m   1807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def create_model(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 16)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 500, 1500)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.1, 1)\n",
    "    rsm = trial.suggest_uniform('rsm', 0.1, 0.99)\n",
    "    #num_leaves = trial.suggest_int(\"num_leaves\", 2, 5000)\n",
    "    #min_child_samples = trial.suggest_int('min_child_samples', 3, 200)\n",
    "    reg_lambda = trial.suggest_int(\"reg_lambda\", 1, 1000)\n",
    "    model = CatBoostRegressor(\n",
    "        learning_rate=learning_rate, \n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth,\n",
    "        rsm = rsm,\n",
    "        reg_lambda = reg_lambda,\n",
    "        #num_leaves=num_leaves, \n",
    "        #min_child_samples=min_child_samples,\n",
    "        random_state=0,\n",
    "        verbose = False\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sampler = TPESampler(seed=0)\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    model.fit(X_trn, y_trn)\n",
    "    preds = model.predict(X_val)\n",
    "    score = np.sqrt(mean_squared_error(y_val,preds))\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "cat_params = study.best_params\n",
    "cat_params['random_state'] = 0\n",
    "cat = CatBoostRegressor(**cat_params, verbose = False)\n",
    "cat.fit(X_trn, y_trn)\n",
    "preds = cat.predict(X_val)\n",
    "print('Optimized Catboost RMSE', np.sqrt(mean_squared_error(y_val, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Fold1============================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-f71f88e96215>\u001b[0m in \u001b[0;36mboosting_cross_val\u001b[1;34m(regressor, train, test, features, name)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m############ Fitting And Predicting #############\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m## Predicting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4838\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4839\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4840\u001b[1;33m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4842\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1803\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1805\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1806\u001b[0m             )\n\u001b[0;32m   1807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_fe_oofs, cat_fe_preds = boosting_cross_val(cat, train_proc, test_proc, features, 'cat')\n",
    "sample_sub['Purchase'] = cat_fe_preds\n",
    "sample_sub.to_csv(r\"D:\\Data Science\\Projects\\Analytics vidya\\Black Friday Sales Prediction\\final\\CAT_FE_Boosting.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(regressor, train, test, features):\n",
    "    N_splits = 5\n",
    "    \n",
    "    oofs = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    \n",
    "    target_col = train[target]\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits = N_splits, shuffle = True)\n",
    "    stratified_target = pd.qcut( train[target], 10, labels = False, duplicates = 'drop')\n",
    "    \n",
    "    for index, (trn_idx, val_idx) in enumerate(folds.split(train, stratified_target)):\n",
    "        print(f'\\n=========================Fold{index+1}============================')\n",
    "        \n",
    "        ####### Getting Train, Validation and Test sets.\n",
    "        \n",
    "        ## Training Set\n",
    "        X_trn, y_trn = train[features].iloc[trn_idx], target_col.iloc[trn_idx]\n",
    "        \n",
    "        ## Validation Set\n",
    "        X_val, y_val = train[features].iloc[val_idx], target_col.iloc[val_idx]\n",
    "        \n",
    "        ## Test Set\n",
    "        X_test = test[features]\n",
    "        ###### Scaling Data ######\n",
    "        scaler = StandardScaler()\n",
    "        _ = scaler.fit(X_trn)\n",
    "\n",
    "        X_trn = scaler.transform(X_trn)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        \n",
    "        ############ Fitting And Predicting #############\n",
    "        _ = regressor.fit(X_trn, y_trn)\n",
    "        \n",
    "        ## Predicting\n",
    "        val_preds = regressor.predict(X_val)\n",
    "        test_preds = regressor.predict(X_test)\n",
    "        \n",
    "        fold_score = np.sqrt( mean_squared_error(y_val, val_preds))\n",
    "        print(f'\\n RMSE score for Validation set is : {fold_score}')\n",
    "        \n",
    "        oofs[val_idx] = val_preds\n",
    "        preds += test_preds / N_splits\n",
    "        \n",
    "    oofs_score = np.sqrt( mean_squared_error(target_col, oofs))\n",
    "    print(f'\\n\\nRMSE score for oofs is {oofs_score}')\n",
    "    \n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = train_proc[[target, 'User_ID']].copy()\n",
    "test_new = test_proc[[target, 'User_ID']].copy()\n",
    "\n",
    "train_new['lgb'] = lgb_fe_oofs\n",
    "test_new['lgb'] = lgb_fe_preds\n",
    "\n",
    "#train_new['cb'] = cat_fe_oofs\n",
    "#test_new['cb'] = cat_fe_preds\n",
    "\n",
    "train_new['xgb'] = xgb_fe_oofs\n",
    "test_new['xgb'] = xgb_fe_preds\n",
    "\n",
    "ens_features = [c for c in train_new.columns if c not in [target, 'User_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_features = ['lgb', 'xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Fold1============================\n",
      "\n",
      " RMSE score for Validation set is : 2420.8209636112333\n",
      "\n",
      "=========================Fold2============================\n",
      "\n",
      " RMSE score for Validation set is : 2412.40119409859\n",
      "\n",
      "=========================Fold3============================\n",
      "\n",
      " RMSE score for Validation set is : 2408.725162723656\n",
      "\n",
      "=========================Fold4============================\n",
      "\n",
      " RMSE score for Validation set is : 2425.385914767702\n",
      "\n",
      "=========================Fold5============================\n",
      "\n",
      " RMSE score for Validation set is : 2414.8601005705746\n",
      "\n",
      "\n",
      "RMSE score for oofs is 2416.446001290232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "\n",
    "ens_oofs, ens_preds = cross_val(clf, train_new, test_new, ens_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub['Purchase'] = ens_preds\n",
    "sample_sub.to_csv(r\"D:\\Data Science\\Projects\\Analytics vidya\\Black Friday Sales Prediction\\Ensemble.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Fold1============================\n",
      "\n",
      " RMSE score for Validation set is : 2416.2809061797616\n",
      "\n",
      "=========================Fold2============================\n",
      "\n",
      " RMSE score for Validation set is : 2418.996482301684\n",
      "\n",
      "=========================Fold3============================\n",
      "\n",
      " RMSE score for Validation set is : 2421.88779049467\n",
      "\n",
      "=========================Fold4============================\n",
      "\n",
      " RMSE score for Validation set is : 2414.9731614071334\n",
      "\n",
      "=========================Fold5============================\n",
      "\n",
      " RMSE score for Validation set is : 2410.956560538801\n",
      "\n",
      "\n",
      "RMSE score for oofs is 2416.6218196826585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LGBMRegressor()\n",
    "\n",
    "ens_oofs, ens_preds = boosting_cross_val(clf, train_new, test_new, ens_features, 'lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
